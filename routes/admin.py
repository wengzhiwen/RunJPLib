from datetime import datetime
from datetime import timedelta
from functools import wraps
import json
import logging
import os
import tempfile
import time
import uuid

from bson.objectid import ObjectId
from flask import Blueprint
from flask import jsonify
from flask import make_response
from flask import redirect
from flask import render_template
from flask import request
from flask import Response
from flask import url_for
from flask_jwt_extended import create_access_token
from flask_jwt_extended import get_jwt_identity
from flask_jwt_extended import set_access_cookies
from flask_jwt_extended import unset_jwt_cookies
from flask_jwt_extended import verify_jwt_in_request
from werkzeug.utils import secure_filename

from utils.blog_generator import BlogGenerator
from utils.mongo_client import get_db
from utils.mongo_client import get_mongo_client
from utils.task_manager import task_manager
from utils.thread_pool_manager import thread_pool_manager

admin_bp = Blueprint(
    "admin", __name__, url_prefix="/admin", template_folder="../templates/admin"
)

PROJECT_ROOT = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))

# --- Adminæ•°æ®åº“æ“ä½œçš„è¾…åŠ©å‡½æ•° ---


def _update_university_in_db(object_id, update_data, university_id):
    """å¼‚æ­¥æ›´æ–°å¤§å­¦ä¿¡æ¯åˆ°æ•°æ®åº“"""
    try:
        db = get_db()
        if db is None:
            logging.error("Adminå¼‚æ­¥æ›´æ–°å¤§å­¦ä¿¡æ¯å¤±è´¥ï¼šæ— æ³•è¿æ¥æ•°æ®åº“")
            return
        db.universities.update_one({"_id": object_id}, update_data)
        logging.info(f"University with ID {university_id} was updated (async).")
    except Exception as e:
        logging.error(f"å¼‚æ­¥æ›´æ–°å¤§å­¦ä¿¡æ¯å¤±è´¥: {e}")


def _save_blog_to_db(blog_data):
    """å¼‚æ­¥ä¿å­˜åšå®¢åˆ°æ•°æ®åº“"""
    try:
        db = get_db()
        if db is None:
            logging.error("Adminå¼‚æ­¥ä¿å­˜åšå®¢å¤±è´¥ï¼šæ— æ³•è¿æ¥æ•°æ®åº“")
            return None

        result = db.blogs.insert_one(blog_data)
        logging.info(f"New blog post created with ID: {result.inserted_id} (async).")
        return str(result.inserted_id)
    except Exception as e:
        logging.error(f"å¼‚æ­¥ä¿å­˜åšå®¢å¤±è´¥: {e}")
        return None


def _update_blog_in_db(object_id, update_data, blog_id):
    """å¼‚æ­¥æ›´æ–°åšå®¢åˆ°æ•°æ®åº“"""
    try:
        db = get_db()
        if db is None:
            logging.error("Adminå¼‚æ­¥æ›´æ–°åšå®¢å¤±è´¥ï¼šæ— æ³•è¿æ¥æ•°æ®åº“")
            return

        db.blogs.update_one({"_id": object_id}, update_data)
        logging.info(f"Blog post with ID {blog_id} was updated (async).")
    except Exception as e:
        logging.error(f"å¼‚æ­¥æ›´æ–°åšå®¢å¤±è´¥: {e}")


def admin_required(fn):

    @wraps(fn)
    def wrapper(*args, **kwargs):
        is_api_request = request.path.startswith("/admin/api/")
        try:
            verify_jwt_in_request(locations=["headers", "cookies"])
            identity = get_jwt_identity()
            if identity != "admin":
                logging.warning("A non-admin identity was found in a valid JWT.")
                if is_api_request:
                    return jsonify(msg="éœ€è¦ç®¡ç†å‘˜æƒé™"), 403
                else:
                    return redirect(url_for("admin.login"))
        except Exception as e:
            logging.warning(f"JWT validation failed for path '{request.path}': {e}")
            if is_api_request:
                return jsonify(msg="Tokenæ— æ•ˆæˆ–å·²è¿‡æœŸ"), 401
            else:
                return redirect(url_for("admin.login"))
        return fn(*args, **kwargs)

    return wrapper


def _get_dashboard_stats():
    """è·å–ä»ªè¡¨ç›˜æ ¸å¿ƒç»Ÿè®¡æ•°æ®çš„è¾…åŠ©å‡½æ•°"""
    db = get_db()
    if db is None:
        logging.error("ä»ªè¡¨ç›˜æ— æ³•è¿æ¥åˆ°æ•°æ®åº“")
        return {"error": "æ•°æ®åº“è¿æ¥å¤±è´¥"}
    stats = {}
    try:
        stats["university_count"] = db.universities.count_documents({})
        stats["blog_count"] = db.blogs.count_documents({})
        twenty_four_hours_ago = datetime.utcnow() - timedelta(hours=24)
        query_24h = {"timestamp": {"$gte": twenty_four_hours_ago}}
        unique_ips = db.access_logs.distinct("ip", query_24h)
        stats["unique_ip_count_24h"] = len(unique_ips)
        query_uni_24h = {
            "timestamp": {"$gte": twenty_four_hours_ago},
            "page_type": "university",
        }
        stats["university_views_24h"] = db.access_logs.count_documents(query_uni_24h)
        query_blog_24h = {
            "timestamp": {"$gte": twenty_four_hours_ago},
            "page_type": "blog",
        }
        stats["blog_views_24h"] = db.access_logs.count_documents(query_blog_24h)
    except Exception as e:
        logging.error(f"æŸ¥è¯¢ä»ªè¡¨ç›˜ç»Ÿè®¡æ•°æ®æ—¶å‡ºé”™: {e}", exc_info=True)
        return {"error": "æŸ¥è¯¢ç»Ÿè®¡æ•°æ®æ—¶å‡ºé”™"}
    return stats


@admin_bp.route("/")
@admin_required
def dashboard():
    """ä»ªè¡¨ç›˜è·¯ç”±ï¼Œå±•ç¤ºç»Ÿè®¡æ•°æ®"""
    stats = _get_dashboard_stats()
    if "error" in stats:
        return render_template("dashboard.html", error=stats["error"])

    client = get_mongo_client()
    expired_premium_universities = []
    if client is not None:

        try:
            today = datetime.utcnow().replace(hour=0, minute=0, second=0, microsecond=0)
            pipeline = [
                {
                    "$group": {
                        "_id": "$university_name",
                        "max_deadline": {"$max": "$deadline"},
                        "has_premium": {"$max": "$is_premium"},
                    }
                },
                {"$match": {"has_premium": True, "max_deadline": {"$lt": today}}},
                {"$sort": {"max_deadline": 1}},
                {
                    "$project": {
                        "_id": 0,
                        "university_name": "$_id",
                        "deadline": "$max_deadline",
                    }
                },
            ]
            expired_premium_universities = list(
                client.RunJPLib.universities.aggregate(pipeline)
            )
        except Exception as e:
            logging.error(f"æŸ¥è¯¢è¿‡æœŸPremiumå­¦æ ¡æ—¶å‡ºé”™: {e}", exc_info=True)

    return render_template(
        "dashboard.html",
        stats=stats,
        expired_premium_universities=expired_premium_universities,
    )


@admin_bp.route("/login")
def login():
    return render_template("login.html")


@admin_bp.route("/logout")
def logout():
    response = make_response(redirect(url_for("admin.login")))
    unset_jwt_cookies(response)
    return response


@admin_bp.route("/api/login", methods=["POST"])
def api_login():
    data = request.get_json()
    if not data:
        logging.error("ç™»å½•å¤±è´¥: è¯·æ±‚ä½“ä¸æ˜¯æœ‰æ•ˆçš„JSONæˆ–Content-Typeå¤´ç¼ºå¤±ã€‚")
        return jsonify({"msg": "æ— æ•ˆçš„è¯·æ±‚æ ¼å¼"}), 400
    access_code = data.get("access_code")
    env_access_code = os.getenv("ACCESS_CODE")
    if not env_access_code:
        logging.error("ä¸¥é‡å®‰å…¨é…ç½®é”™è¯¯: ç¯å¢ƒå˜é‡ ACCESS_CODE æœªè®¾ç½®ã€‚")
        return jsonify({"msg": "æœåŠ¡å™¨é…ç½®é”™è¯¯"}), 500
    if not access_code or access_code != env_access_code:
        logging.warning("æ”¶åˆ°ä¸€ä¸ªé”™è¯¯çš„è®¿é—®ç ã€‚")
        return jsonify({"msg": "è®¿é—®ç é”™è¯¯"}), 401
    logging.info("ç®¡ç†å‘˜ç™»å½•æˆåŠŸã€‚")
    access_token = create_access_token(identity="admin")
    response = jsonify(msg="ç™»å½•æˆåŠŸ")
    set_access_cookies(response, access_token)
    return response


@admin_bp.route("/api/verify_token")
@admin_required
def verify_token():
    return jsonify(status="ok")


# --- Data Management Pages ---
@admin_bp.route("/manage/universities")
@admin_required
def manage_universities_page():
    return render_template("manage_universities.html")


@admin_bp.route("/manage/blogs")
@admin_required
def manage_blogs_page():
    return render_template("manage_blogs.html")


# --- Data Management APIs ---
@admin_bp.route("/api/universities", methods=["GET"])
@admin_required
def get_universities():
    db = get_db()
    if db is None:
        logging.error("[Admin API] Get universities failed: DB connection error.")
        return jsonify({"error": "æ•°æ®åº“è¿æ¥å¤±è´¥"}), 500

    try:
        logging.debug("[Admin API] Fetching universities from database...")
        projection = {"content": 0, "source_path": 0}
        # ä¼˜åŒ–æ’åºï¼šæŒ‰ _id é€†åºæ’åˆ—ï¼Œå®ç°æŒ‰åˆ›å»ºæ—¶é—´å€’åº
        cursor = db.universities.find({}, projection).sort("_id", -1)

        universities = list(cursor)

        for u in universities:
            u["_id"] = str(u["_id"])
            # ç¡®ä¿ deadline å­—æ®µæ˜¯ ISO æ ¼å¼çš„å­—ç¬¦ä¸²ï¼Œæ–¹ä¾¿å‰ç«¯è§£æ
            if u.get("deadline") and isinstance(u["deadline"], datetime):
                u["deadline"] = u["deadline"].isoformat()

        logging.info(
            f"[Admin API] Successfully fetched {len(universities)} university documents."
        )
        if universities:
            logging.debug(
                f"[Admin API] First university document sample: {universities[0]}"
            )

        return jsonify(universities)
    except Exception as e:
        logging.error(
            f"[Admin API] An exception occurred while fetching universities: {e}",
            exc_info=True,
        )
        return jsonify({"error": "æœåŠ¡å™¨å†…éƒ¨é”™è¯¯"}), 500


@admin_bp.route("/edit_university/<university_id>", methods=["GET", "POST"])
@admin_required
def edit_university(university_id):
    """
    ç¼–è¾‘å¤§å­¦ä¿¡æ¯çš„é¡µé¢å’Œå¤„ç†é€»è¾‘
    GET: æ˜¾ç¤ºç¼–è¾‘è¡¨å•
    POST: æ›´æ–°å¤§å­¦ä¿¡æ¯
    """
    db = get_db()
    if db is None:
        return render_template("edit_university.html", error="æ•°æ®åº“è¿æ¥å¤±è´¥")

    try:
        object_id = ObjectId(university_id)
    except Exception:
        return render_template("404.html"), 404

    if request.method == "POST":
        university_name = request.form.get("university_name", "").strip()
        university_name_zh = request.form.get("university_name_zh", "").strip()
        is_premium = request.form.get("is_premium") == "true"
        deadline_str = request.form.get("deadline", "")
        basic_analysis_report = request.form.get("basic_analysis_report", "").strip()

        if not university_name:
            university = db.universities.find_one({"_id": object_id})
            return render_template(
                "edit_university.html", university=university, error="å¤§å­¦åç§°ä¸èƒ½ä¸ºç©º"
            )

        update_data = {
            "$set": {
                "university_name": university_name,
                "university_name_zh": university_name_zh,
                "is_premium": is_premium,
                "content.report_md": basic_analysis_report,
                "last_modified": datetime.utcnow(),
            }
        }

        if deadline_str:
            try:
                # å°† YYYY-MM-DD æ ¼å¼çš„å­—ç¬¦ä¸²è½¬æ¢ä¸º datetime å¯¹è±¡
                update_data["$set"]["deadline"] = datetime.strptime(
                    deadline_str, "%Y-%m-%d"
                )
            except ValueError:
                # å¦‚æœæ—¥æœŸæ ¼å¼ä¸æ­£ç¡®ï¼Œè¿”å›é”™è¯¯ä¿¡æ¯
                university = db.universities.find_one({"_id": object_id})
                return render_template(
                    "edit_university.html",
                    university=university,
                    error="æ—¥æœŸæ ¼å¼ä¸æ­£ç¡®ï¼Œè¯·ä½¿ç”¨ YYYY-MM-DD æ ¼å¼ã€‚",
                )

        # å°è¯•å¼‚æ­¥æ›´æ–°æ•°æ®åº“
        success = thread_pool_manager.submit_admin_task(
            _update_university_in_db, object_id, update_data, university_id
        )

        if not success:
            # çº¿ç¨‹æ± æ»¡ï¼ŒåŒæ­¥æ‰§è¡Œ
            logging.warning("Adminçº¿ç¨‹æ± ç¹å¿™ï¼ŒåŒæ­¥æ›´æ–°å¤§å­¦ä¿¡æ¯")
            try:
                db.universities.update_one({"_id": object_id}, update_data)
                logging.info(f"University with ID {university_id} was updated (sync).")
            except Exception as e:
                logging.error(f"åŒæ­¥æ›´æ–°å¤§å­¦ä¿¡æ¯å¤±è´¥: {e}")
                return render_template(
                    "edit_university.html",
                    university=db.universities.find_one({"_id": object_id}),
                    error="æ›´æ–°å¤±è´¥ï¼Œè¯·é‡è¯•",
                )
        else:
            logging.info(
                f"University with ID {university_id} update task submitted to thread pool."
            )

        return redirect(url_for("admin.manage_universities_page"))

    # GET è¯·æ±‚
    university = db.universities.find_one({"_id": object_id})
    if not university:
        return render_template("404.html"), 404

    return render_template("edit_university.html", university=university)


@admin_bp.route("/api/universities/<item_id>", methods=["DELETE"])
@admin_required
def delete_university(item_id):
    db = get_db()
    if db is None:
        return jsonify({"error": "æ•°æ®åº“è¿æ¥å¤±è´¥"}), 500

    db.universities.delete_one({"_id": ObjectId(item_id)})
    return jsonify({"message": "åˆ é™¤æˆåŠŸ"})


@admin_bp.route("/api/universities", methods=["DELETE"])
@admin_required
def clear_universities():
    db = get_db()
    if db is None:
        return jsonify({"error": "æ•°æ®åº“è¿æ¥å¤±è´¥"}), 500

    db.universities.delete_many({})
    return jsonify({"message": "æ•°æ®é›†åˆå·²æ¸…ç©º"})


@admin_bp.route("/api/blogs", methods=["GET"])
@admin_required
def get_blogs():
    db = get_db()
    if db is None:
        return jsonify({"error": "æ•°æ®åº“è¿æ¥å¤±è´¥"}), 500

    cursor = db.blogs.find({}).sort("publication_date", -1)
    blogs = []
    for b in cursor:
        b["_id"] = str(b["_id"])
        html_status = "æœªç”Ÿæˆ"
        md_last_updated = b.get("md_last_updated")
        html_last_updated = b.get("html_last_updated")
        if html_last_updated:
            html_status = "æœ€æ–°"
            if md_last_updated and md_last_updated > html_last_updated:
                html_status = "å¾…æ›´æ–°"
        b["html_status"] = html_status
        if md_last_updated:
            b["md_last_updated"] = md_last_updated.strftime("%Y-%m-%d %H:%M:%S")
        if html_last_updated:
            b["html_last_updated"] = html_last_updated.strftime("%Y-%m-%d %H:%M:%S")
        b.pop("content_md", None)
        b.pop("content_html", None)
        blogs.append(b)
    return jsonify(blogs)


@admin_bp.route("/api/blogs/<item_id>", methods=["DELETE"])
@admin_required
def delete_blog(item_id):
    db = get_db()
    if db is None:
        return jsonify({"error": "æ•°æ®åº“è¿æ¥å¤±è´¥"}), 500

    db.blogs.delete_one({"_id": ObjectId(item_id)})
    return jsonify({"message": "åˆ é™¤æˆåŠŸ"})


@admin_bp.route("/api/blogs", methods=["DELETE"])
@admin_required
def clear_blogs():
    db = get_db()
    if db is None:
        return jsonify({"error": "æ•°æ®åº“è¿æ¥å¤±è´¥"}), 500

    db.blogs.delete_many({})
    return jsonify({"message": "æ•°æ®é›†åˆå·²æ¸…ç©º"})


# --- Blog Creator ---


@admin_bp.route("/blog/create")
@admin_required
def create_blog_page():
    """Renders the blog creation page."""
    return render_template("create_blog.html")


@admin_bp.route("/api/universities/search", methods=["GET"])
@admin_required
def search_universities():
    """
    Searches for universities by name.
    Accepts a 'q' query parameter for the search term.
    """
    query = request.args.get("q", "").strip()
    if not query:
        return jsonify([])

    db = get_db()
    if db is None:
        return jsonify({"error": "æ•°æ®åº“è¿æ¥å¤±è´¥"}), 500

    try:
        # Search for universities where the name contains the query string (case-insensitive)
        universities = list(
            db.universities.find(
                {"university_name": {"$regex": query, "$options": "i"}},
                {"_id": 1, "university_name": 1},
            ).limit(20)
        )  # Limit to 20 results for performance

        for u in universities:
            u["_id"] = str(u["_id"])

        return jsonify(universities)
    except Exception as e:
        logging.error(f"[Admin API] University search failed: {e}", exc_info=True)
        return jsonify({"error": "æœåŠ¡å™¨å†…éƒ¨é”™è¯¯"}), 500


@admin_bp.route("/api/blog/generate", methods=["POST"])
@admin_required
def generate_blog():
    """
    Generates blog content using the AI generator.
    Expects a JSON payload with 'university_ids', 'user_prompt', and 'system_prompt'.
    """
    data = request.get_json()
    if not data:
        return jsonify({"error": "æ— æ•ˆçš„è¯·æ±‚æ ¼å¼"}), 400

    university_ids = data.get("university_ids", [])
    user_prompt = data.get("user_prompt", "")
    system_prompt = data.get("system_prompt", "")
    mode = data.get("mode", "expand")  # Default to expand for safety

    if not system_prompt:
        return jsonify({"error": "ç³»ç»Ÿæç¤ºè¯ä¸èƒ½ä¸ºç©º"}), 400

    # Validate inputs based on mode
    if mode in ["expand", "compare"] and not university_ids:
        return jsonify({"error": "è¯¥æ¨¡å¼éœ€è¦è‡³å°‘é€‰æ‹©ä¸€æ‰€å¤§å­¦"}), 400
    if mode == "compare" and len(university_ids) < 2:
        return jsonify({"error": "å¯¹æ¯”åˆ†ææ¨¡å¼éœ€è¦è‡³å°‘é€‰æ‹©ä¸¤æ‰€å¤§å­¦"}), 400
    if mode == "user_prompt_only" and not user_prompt:
        return jsonify({"error": "è¯¥æ¨¡å¼éœ€è¦å¡«å†™ç”¨æˆ·æç¤ºè¯"}), 400

    try:
        generator = BlogGenerator()
        result = generator.generate_blog_content(
            mode, university_ids, user_prompt, system_prompt
        )
        if result:
            return jsonify(result)
        else:
            return jsonify({"error": "ç”Ÿæˆæ–‡ç« å¤±è´¥"}), 500
    except Exception as e:
        logging.error(f"[Admin API] Blog generation failed: {e}", exc_info=True)
        return jsonify({"error": "æœåŠ¡å™¨å†…éƒ¨é”™è¯¯"}), 500


@admin_bp.route("/api/blog/save", methods=["POST"])
@admin_required
def save_blog():
    """
    Saves a new blog post to the database.
    Expects a JSON payload with 'title' and 'content_md'.
    """
    data = request.get_json()
    if not data or "title" not in data or "content_md" not in data:
        return jsonify({"error": "æ— æ•ˆçš„è¯·æ±‚æ ¼å¼ï¼Œéœ€è¦'title'å’Œ'content_md'"}), 400

    title = data["title"].strip()
    content_md = data["content_md"].strip()

    if not title or not content_md:
        return jsonify({"error": "æ ‡é¢˜å’Œå†…å®¹ä¸èƒ½ä¸ºç©º"}), 400

    db = get_db()
    if db is None:
        return jsonify({"error": "æ•°æ®åº“è¿æ¥å¤±è´¥"}), 500

    try:
        # Create a URL-friendly title
        url_title = title.lower().replace(" ", "-").replace("/", "-")
        # Remove any characters that are not safe for URLs
        url_title = "".join(c for c in url_title if c.isalnum() or c == "-")

        new_blog = {
            "title": title,
            "url_title": url_title,
            "publication_date": datetime.now().strftime("%Y-%m-%d"),
            "created_at": datetime.now(),
            "md_last_updated": datetime.now(),
            "html_last_updated": None,
            "content_md": content_md,
            "content_html": None,
        }

        # å°è¯•å¼‚æ­¥ä¿å­˜åšå®¢
        success = thread_pool_manager.submit_admin_task(_save_blog_to_db, new_blog)

        if not success:
            # çº¿ç¨‹æ± æ»¡ï¼ŒåŒæ­¥æ‰§è¡Œ
            logging.warning("Adminçº¿ç¨‹æ± ç¹å¿™ï¼ŒåŒæ­¥ä¿å­˜åšå®¢")
            try:
                result = db.blogs.insert_one(new_blog)
                logging.info(
                    f"New blog post created with ID: {result.inserted_id} (sync)."
                )
                return jsonify(
                    {"message": "æ–‡ç« ä¿å­˜æˆåŠŸ", "blog_id": str(result.inserted_id)}
                )
            except Exception as sync_e:
                logging.error(f"åŒæ­¥ä¿å­˜åšå®¢å¤±è´¥: {sync_e}")
                return jsonify({"error": "ä¿å­˜å¤±è´¥ï¼Œè¯·é‡è¯•"}), 500
        else:
            # å¼‚æ­¥ä»»åŠ¡å·²æäº¤ï¼Œæ— æ³•ç«‹å³è·å–blog_idï¼Œä½†é€šå¸¸Adminç•Œé¢å¯ä»¥æ¥å—
            logging.info("Blog save task submitted to thread pool.")
            return jsonify({"message": "æ–‡ç« ä¿å­˜ä»»åŠ¡å·²æäº¤", "blog_id": "pending"})
    except Exception as e:
        logging.error(f"[Admin API] Failed to save blog: {e}", exc_info=True)
        return jsonify({"error": "æœåŠ¡å™¨å†…éƒ¨é”™è¯¯"}), 500


@admin_bp.route("/blog/edit/<blog_id>", methods=["GET", "POST"])
@admin_required
def edit_blog(blog_id):
    """
    Handles editing of a blog post.
    GET: Displays the edit form.
    POST: Updates the blog post in the database.
    """
    db = get_db()
    if db is None:
        return render_template("edit_blog.html", error="æ•°æ®åº“è¿æ¥å¤±è´¥")

    try:
        object_id = ObjectId(blog_id)
    except Exception:
        return render_template("404.html"), 404

    if request.method == "POST":
        title = request.form.get("title", "").strip()
        content_md = request.form.get("content_md", "").strip()

        if not title or not content_md:
            blog = db.blogs.find_one({"_id": object_id})
            return render_template(
                "edit_blog.html", blog=blog, error="æ ‡é¢˜å’Œå†…å®¹ä¸èƒ½ä¸ºç©º"
            )

        # Create a URL-friendly title
        url_title = title.lower().replace(" ", "-").replace("/", "-")
        url_title = "".join(c for c in url_title if c.isalnum() or c == "-")

        update_data = {
            "$set": {
                "title": title,
                "url_title": url_title,
                "content_md": content_md,
                "md_last_updated": datetime.now(),
            }
        }

        # å°è¯•å¼‚æ­¥æ›´æ–°åšå®¢
        success = thread_pool_manager.submit_admin_task(
            _update_blog_in_db, object_id, update_data, blog_id
        )

        if not success:
            # çº¿ç¨‹æ± æ»¡ï¼ŒåŒæ­¥æ‰§è¡Œ
            logging.warning("Adminçº¿ç¨‹æ± ç¹å¿™ï¼ŒåŒæ­¥æ›´æ–°åšå®¢")
            try:
                db.blogs.update_one({"_id": object_id}, update_data)
                logging.info(f"Blog post with ID {blog_id} was updated (sync).")
            except Exception as e:
                logging.error(f"åŒæ­¥æ›´æ–°åšå®¢å¤±è´¥: {e}")
                return render_template(
                    "edit_blog.html",
                    blog=db.blogs.find_one({"_id": object_id}),
                    error="æ›´æ–°å¤±è´¥ï¼Œè¯·é‡è¯•",
                )
        else:
            logging.info(
                f"Blog post with ID {blog_id} update task submitted to thread pool."
            )

        return redirect(url_for("admin.manage_blogs_page"))

    # For GET request
    blog = db.blogs.find_one({"_id": object_id})
    if not blog:
        return render_template("404.html"), 404

    # To ensure ObjectId is JSON serializable for the template if needed, though we're passing the raw object
    blog["_id"] = str(blog["_id"])

    return render_template("edit_blog.html", blog=blog)


# --- PDF Processing Pages ---
@admin_bp.route("/pdf/processor")
@admin_required
def pdf_processor_page():
    """PDFå¤„ç†å™¨é¡µé¢"""
    return render_template("pdf_processor.html")


@admin_bp.route("/pdf/tasks")
@admin_required
def pdf_tasks_page():
    """PDFä»»åŠ¡åˆ—è¡¨é¡µé¢"""
    return render_template("pdf_tasks.html")


@admin_bp.route("/pdf/task/<task_id>")
@admin_required
def pdf_task_detail_page(task_id):
    """PDFä»»åŠ¡è¯¦æƒ…é¡µé¢"""
    task = task_manager.get_task_status(task_id)
    if not task:
        return render_template("404.html"), 404
    return render_template("pdf_task_detail.html", task=task)


# --- Analytics: Unique IPs in last 24h ---
@admin_bp.route("/analytics/unique_ips")
@admin_required
def unique_ips_page():
    """å±•ç¤ºæœ€è¿‘24å°æ—¶çš„ç‹¬ç«‹IPåˆ—è¡¨åŠç›¸å…³ä¿¡æ¯ï¼ˆæ— SSEï¼‰ã€‚"""
    db = get_db()
    if db is None:
        return render_template("unique_ips.html", error="æ•°æ®åº“è¿æ¥å¤±è´¥", items=[])

        # ç¡®ä¿mmdbæ–‡ä»¶å¯ç”¨
    from utils.ip_geo import ip_geo_manager

    logging.info("ğŸ”§ æ£€æŸ¥mmdbæ–‡ä»¶å¯ç”¨æ€§...")
    mmdb_available = ip_geo_manager.ensure_mmdb_available()
    logging.info(f"ğŸ“ mmdbæ–‡ä»¶çŠ¶æ€: {'å¯ç”¨' if mmdb_available else 'ä¸å¯ç”¨'}")

    twenty_four_hours_ago = datetime.utcnow() - timedelta(hours=24)
    logging.info(f"â° æŸ¥è¯¢æ—¶é—´èŒƒå›´: {twenty_four_hours_ago} è‡³ä»Š")

    try:
        pipeline = [
            {"$match": {"timestamp": {"$gte": twenty_four_hours_ago}}},
            {
                "$group": {
                    "_id": "$ip",
                    "first_seen": {"$min": "$timestamp"},
                    "last_seen": {"$max": "$timestamp"},
                    "visit_count": {"$sum": 1},
                    "page_types": {"$addToSet": "$page_type"},
                }
            },
            {"$sort": {"last_seen": -1}},
        ]

        logging.info("ğŸ” æ‰§è¡ŒMongoDBèšåˆæŸ¥è¯¢...")
        results = list(db.access_logs.aggregate(pipeline))
        logging.info(f"ğŸ“Š æŸ¥è¯¢åˆ° {len(results)} ä¸ªç‹¬ç«‹IP")

        items = []
        ips_to_lookup = []

        for r in results:
            ip = r.get("_id")

            # æ£€æŸ¥è¯¥IPæ˜¯å¦å·²æœ‰åœ°ç†ä¿¡æ¯ï¼ˆä»ä»»æ„ä¸€æ¡è®¿é—®è®°å½•ä¸­è·å–ï¼‰
            geo_info = None
            if mmdb_available:
                # æŸ¥è¯¢è¯¥IPçš„ä»»æ„ä¸€æ¡è®¿é—®è®°å½•ï¼Œçœ‹æ˜¯å¦å·²æœ‰åœ°ç†ä¿¡æ¯
                sample_log = db.access_logs.find_one(
                    {"ip": ip, "geo_info": {"$exists": True}}
                )
                if sample_log and sample_log.get("geo_info"):
                    geo_info = sample_log["geo_info"]
                    logging.debug(
                        f"âœ… ä»è®¿é—®è®°å½•ä¸­æ‰¾åˆ°åœ°ç†ä¿¡æ¯: {ip} -> {geo_info.get('city', 'N/A')}"
                    )
                else:
                    ips_to_lookup.append(ip)
                    logging.debug(f"â“ IPéœ€è¦è§£æåœ°ç†ä¿¡æ¯: {ip}")

            item = {
                "ip": ip,
                "first_seen": r.get("first_seen"),
                "last_seen": r.get("last_seen"),
                "visit_count": r.get("visit_count", 0),
                "page_types": r.get("page_types", []),
                "geo_info": geo_info,
            }
            items.append(item)

        logging.info(f"ğŸ¯ å‡†å¤‡å¤„ç† {len(ips_to_lookup)} ä¸ªIPçš„åœ°ç†ä¿¡æ¯")

        # æ‰¹é‡æŸ¥è¯¢åœ°ç†ä¿¡æ¯å¹¶æ›´æ–°æ•°æ®åº“
        if mmdb_available and ips_to_lookup:
            _batch_update_geo_info(db, ips_to_lookup, items)
        else:
            logging.info("â­ï¸ è·³è¿‡åœ°ç†ä¿¡æ¯å¤„ç† (mmdbä¸å¯ç”¨æˆ–æ— IPéœ€è¦å¤„ç†)")

        logging.info(f"âœ… é¡µé¢æ¸²æŸ“å®Œæˆï¼Œå…± {len(items)} ä¸ªIP")
        return render_template(
            "unique_ips.html", items=items, mmdb_available=mmdb_available
        )
    except Exception as e:
        logging.error(f"æŸ¥è¯¢ç‹¬ç«‹IPç»Ÿè®¡å¤±è´¥: {e}", exc_info=True)
        return render_template("unique_ips.html", error="æŸ¥è¯¢å¤±è´¥", items=[])


def _batch_update_geo_info(db, ips_to_lookup, items):
    """æ‰¹é‡æ›´æ–°IPåœ°ç†ä¿¡æ¯åˆ°æ•°æ®åº“ï¼ˆåµŒå…¥æ–¹æ¡ˆï¼‰"""
    from utils.ip_geo import ip_geo_manager

    try:
        logging.info(f"ğŸ” å¼€å§‹æ‰¹é‡æ›´æ–°åœ°ç†ä¿¡æ¯ï¼Œæ€»IPæ•°é‡: {len(ips_to_lookup)}")

        # æ‰¹é‡å¤„ç†ç¼ºå¤±çš„IP
        batch_size = 200  # é™åˆ¶æ‰¹é‡å¤„ç†æ•°é‡
        processed_count = 0
        skipped_count = 0

        logging.info(f"âš™ï¸ æ‰¹é‡å¤„ç†é™åˆ¶: {batch_size} ä¸ªIP")

        for ip in ips_to_lookup:
            if processed_count >= batch_size:
                logging.info(
                    f"â¹ï¸ è¾¾åˆ°æ‰¹é‡å¤„ç†é™åˆ¶ {batch_size}ï¼Œè·³è¿‡å‰©ä½™ {len(ips_to_lookup) - processed_count} ä¸ªIP"
                )
                break

            # å¤„ç†å¤šIPåœ°å€çš„æƒ…å†µï¼šå–ç¬¬ä¸€ä¸ªIPè¿›è¡Œåœ°ç†ä¿¡æ¯è§£æ
            original_ip = ip
            if "," in ip or " " in ip:
                # å–ç¬¬ä¸€ä¸ªIPåœ°å€è¿›è¡Œåœ°ç†ä¿¡æ¯è§£æ
                first_ip = ip.split(",")[0].strip()
                logging.info(
                    f"ğŸ”„ å¤šIPåœ°å€å¤„ç†: '{ip}' -> ä½¿ç”¨ç¬¬ä¸€ä¸ªIP '{first_ip}' è¿›è¡Œåœ°ç†ä¿¡æ¯è§£æ"
                )
                ip = first_ip
            elif not ip:
                logging.warning(f"è·³è¿‡ç©ºIPåœ°å€")
                skipped_count += 1
                continue

            # æŸ¥è¯¢æ–°çš„åœ°ç†ä¿¡æ¯
            logging.debug(f"ğŸ” æŸ¥è¯¢IP: {ip}")
            geo_data = ip_geo_manager.lookup_ip(ip)

            if geo_data:
                logging.debug(
                    f"ğŸ“ è§£ææˆåŠŸ: {ip} -> {geo_data.get('city', 'N/A')}, {geo_data.get('country_name', 'N/A')}"
                )

                # å‡†å¤‡åœ°ç†ä¿¡æ¯æ•°æ®
                geo_info = {
                    "country_code": geo_data.get("country_code"),
                    "country_name": geo_data.get("country_name"),
                    "city": geo_data.get("city"),
                    "latitude": geo_data.get("latitude"),
                    "longitude": geo_data.get("longitude"),
                    "mmdb_version": "1.0",
                    "geo_updated_at": datetime.utcnow(),
                }

                try:
                    # æ›´æ–°æ‰€æœ‰è¯¥IPçš„è®¿é—®è®°å½•ï¼Œæ·»åŠ åœ°ç†ä¿¡æ¯
                    # æ³¨æ„ï¼šä½¿ç”¨original_ipè¿›è¡Œæ•°æ®åº“æŸ¥è¯¢ï¼Œå› ä¸ºæ•°æ®åº“ä¸­å­˜å‚¨çš„æ˜¯å®Œæ•´çš„IPå­—ç¬¦ä¸²
                    update_result = db.access_logs.update_many(
                        {"ip": original_ip}, {"$set": {"geo_info": geo_info}}
                    )

                    logging.debug(
                        f"ğŸ’¾ æ›´æ–°è®¿é—®è®°å½•: '{original_ip}' -> {update_result.modified_count} æ¡è®°å½•"
                    )

                    # åŒæ—¶ä¿å­˜åˆ°ip_geo_cacheä½œä¸ºå¤‡ä»½
                    # ç¼“å­˜ä¸­ä½¿ç”¨è§£æåçš„å•ä¸ªIPä½œä¸ºkey
                    geo_doc = {"ip": ip, **geo_info}
                    db.ip_geo_cache.replace_one({"ip": ip}, geo_doc, upsert=True)
                    logging.debug(f"ğŸ’¾ ä¿å­˜åˆ°ç¼“å­˜: {ip}")

                    # æ›´æ–°itemsä¸­çš„åœ°ç†ä¿¡æ¯
                    for item in items:
                        if item["ip"] == original_ip:
                            item["geo_info"] = geo_info
                            break

                    processed_count += 1

                except Exception as e:
                    logging.warning(f"âŒ æ›´æ–°IP {ip} åœ°ç†ä¿¡æ¯å¤±è´¥: {e}")
                    skipped_count += 1
            else:
                logging.debug(f"â“ æ— æ³•è§£æIP: {ip} (å¯èƒ½æ˜¯ç§æœ‰IPæˆ–æ— è®°å½•)")
                skipped_count += 1

        # æ€»ç»“æ—¥å¿—
        logging.info("ğŸ“Š æ‰¹é‡æ›´æ–°å®Œæˆ:")
        logging.info(f"  - æ–°è§£æå¹¶åµŒå…¥: {processed_count} ä¸ªIP")
        logging.info(f"  - è·³è¿‡/å¤±è´¥: {skipped_count} ä¸ªIP")
        logging.info(f"  - å‰©ä½™æœªå¤„ç†: {len(ips_to_lookup) - processed_count} ä¸ªIP")

        if processed_count > 0:
            logging.info(f"ğŸ‰ æˆåŠŸæ›´æ–°äº† {processed_count} ä¸ªIPçš„åœ°ç†ä¿¡æ¯åˆ°è®¿é—®è®°å½•ä¸­")

    except Exception as e:
        logging.error(f"âŒ æ‰¹é‡æ›´æ–°åœ°ç†ä¿¡æ¯å¤±è´¥: {e}", exc_info=True)


# --- PDF Processing APIs ---
@admin_bp.route("/api/pdf/upload", methods=["POST"])
@admin_required
def upload_pdf():
    """ä¸Šä¼ PDFæ–‡ä»¶å¹¶å¼€å§‹å¤„ç†"""
    try:
        # æ£€æŸ¥æ–‡ä»¶
        if "pdf_file" not in request.files:
            return jsonify({"error": "æ²¡æœ‰ä¸Šä¼ æ–‡ä»¶"}), 400

        file = request.files["pdf_file"]
        if file.filename == "":
            return jsonify({"error": "æ²¡æœ‰é€‰æ‹©æ–‡ä»¶"}), 400

        if not file.filename.lower().endswith(".pdf"):
            return jsonify({"error": "åªæ”¯æŒPDFæ–‡ä»¶"}), 400

        # è·å–å¤§å­¦åç§°
        university_name = request.form.get("university_name", "").strip()
        if not university_name:
            return jsonify({"error": "è¯·è¾“å…¥å¤§å­¦åç§°"}), 400

        # ä¿å­˜æ–‡ä»¶åˆ°ä¸´æ—¶ç›®å½•
        # original_filename ä¿ç•™ç”¨æˆ·åŸå§‹æ–‡ä»¶åç”¨äºæ˜¾ç¤ºï¼ˆå«ä¸­æ–‡ã€æ—¥æ–‡ã€å¥ç‚¹ç­‰å­—ç¬¦ï¼‰
        original_filename = file.filename
        # ç‰©ç†å­˜å‚¨ä»ä½¿ç”¨å®‰å…¨æ–‡ä»¶åï¼Œé¿å…è·¯å¾„ä¸ç‰¹æ®Šå­—ç¬¦é—®é¢˜
        safe_filename = secure_filename(file.filename)
        temp_filename = f"{uuid.uuid4().hex}_{safe_filename}"

        # åˆ›å»ºä¸´æ—¶ç›®å½•
        temp_dir = os.path.join(tempfile.gettempdir(), "pdf_uploads")
        os.makedirs(temp_dir, exist_ok=True)

        temp_filepath = os.path.join(temp_dir, temp_filename)
        file.save(temp_filepath)

        # åˆ›å»ºå¤„ç†ä»»åŠ¡
        task_id = task_manager.create_task(
            university_name=university_name,
            pdf_file_path=temp_filepath,
            original_filename=original_filename,
        )

        if task_id:
            return jsonify({"message": "ä»»åŠ¡åˆ›å»ºæˆåŠŸ", "task_id": task_id})
        else:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            try:
                os.remove(temp_filepath)
            except OSError:
                pass
            return jsonify({"error": "åˆ›å»ºä»»åŠ¡å¤±è´¥"}), 500

    except Exception as e:
        logging.error(f"[Admin API] PDFä¸Šä¼ å¤±è´¥: {e}", exc_info=True)
        return jsonify({"error": "æœåŠ¡å™¨å†…éƒ¨é”™è¯¯"}), 500


@admin_bp.route("/api/pdf/tasks", methods=["GET"])
@admin_required
def get_pdf_tasks():
    """è·å–PDFå¤„ç†ä»»åŠ¡åˆ—è¡¨"""
    try:
        limit = request.args.get("limit", 50, type=int)
        tasks = task_manager.get_all_tasks(limit=limit)

        # æ ¼å¼åŒ–æ—¶é—´
        for task in tasks:
            if "created_at" in task:
                task["created_at_str"] = task["created_at"].strftime(
                    "%Y-%m-%d %H:%M:%S"
                )
            if "updated_at" in task:
                task["updated_at_str"] = task["updated_at"].strftime(
                    "%Y-%m-%d %H:%M:%S"
                )

        return jsonify(tasks)

    except Exception as e:
        logging.error(f"[Admin API] è·å–PDFä»»åŠ¡åˆ—è¡¨å¤±è´¥: {e}", exc_info=True)
        return jsonify({"error": "æœåŠ¡å™¨å†…éƒ¨é”™è¯¯"}), 500


@admin_bp.route("/api/pdf/task/<task_id>", methods=["GET"])
@admin_required
def get_pdf_task(task_id):
    """è·å–å•ä¸ªPDFå¤„ç†ä»»åŠ¡çš„è¯¦ç»†ä¿¡æ¯"""
    try:
        task = task_manager.get_task_status(task_id)
        if not task:
            return jsonify({"error": "ä»»åŠ¡ä¸å­˜åœ¨"}), 404

        # æ ¼å¼åŒ–æ—¶é—´
        if "created_at" in task:
            task["created_at_str"] = task["created_at"].strftime("%Y-%m-%d %H:%M:%S")
        if "updated_at" in task:
            task["updated_at_str"] = task["updated_at"].strftime("%Y-%m-%d %H:%M:%S")

        # æ ¼å¼åŒ–æ—¥å¿—æ—¶é—´
        if "logs" in task:
            for log in task["logs"]:
                if "timestamp" in log:
                    log["timestamp_str"] = log["timestamp"].strftime("%H:%M:%S")

        return jsonify(task)

    except Exception as e:
        logging.error(f"[Admin API] è·å–PDFä»»åŠ¡è¯¦æƒ…å¤±è´¥: {e}", exc_info=True)
        return jsonify({"error": "æœåŠ¡å™¨å†…éƒ¨é”™è¯¯"}), 500


@admin_bp.route("/api/pdf/queue_status", methods=["GET"])
@admin_required
def get_queue_status():
    """è·å–å¤„ç†é˜Ÿåˆ—çŠ¶æ€"""
    try:
        status = task_manager.get_queue_status()
        return jsonify(status)
    except Exception as e:
        logging.error(f"[Admin API] è·å–é˜Ÿåˆ—çŠ¶æ€å¤±è´¥: {e}", exc_info=True)
        return jsonify({"error": "æœåŠ¡å™¨å†…éƒ¨é”™è¯¯"}), 500


@admin_bp.route("/api/thread_pool/status", methods=["GET"])
@admin_required
def get_thread_pool_status():
    """è·å–çº¿ç¨‹æ± çŠ¶æ€"""
    try:
        stats = thread_pool_manager.get_pool_stats()
        return jsonify(stats)
    except Exception as e:
        logging.error(f"[Admin API] è·å–çº¿ç¨‹æ± çŠ¶æ€å¤±è´¥: {e}", exc_info=True)
        return jsonify({"error": "æœåŠ¡å™¨å†…éƒ¨é”™è¯¯"}), 500


@admin_bp.route("/api/dashboard-stream")
@admin_required
def dashboard_stream():
    """ä½¿ç”¨SSEæ¨é€ä»ªè¡¨ç›˜çš„å®æ—¶æ•°æ®"""

    def event_stream():
        last_data = None
        while True:
            try:
                # è·å–æ ¸å¿ƒç»Ÿè®¡æ•°æ®
                stats_data = _get_dashboard_stats()
                # è·å–çº¿ç¨‹æ± çŠ¶æ€
                pool_data = thread_pool_manager.get_pool_stats()

                # åˆå¹¶æ•°æ®
                combined_data = {"stats": stats_data, "pools": pool_data}

                current_data = json.dumps(combined_data, default=str)

                # ä»…åœ¨æ•°æ®æœ‰å˜åŒ–æ—¶å‘é€
                if current_data != last_data:
                    yield f"data: {current_data}\n\n"
                    last_data = current_data

            except Exception as e:
                logging.error(f"Error in SSE dashboard stream: {e}", exc_info=True)
                error_data = json.dumps({"error": "An internal error occurred"})
                yield f"event: error\ndata: {error_data}\n\n"

            # æ¯30ç§’æ£€æŸ¥ä¸€æ¬¡æ›´æ–°
            time.sleep(30)

    return Response(event_stream(), mimetype="text/event-stream")


@admin_bp.route("/api/pdf/task-stream")
@admin_required
def task_stream():
    """ä½¿ç”¨SSEæ¨é€ä»»åŠ¡åˆ—è¡¨å’Œé˜Ÿåˆ—çŠ¶æ€çš„æ›´æ–°"""

    def event_stream():
        last_tasks_data = None
        last_queue_data = None
        while True:
            try:
                # è·å–æœ€æ–°æ•°æ®
                tasks = task_manager.get_all_tasks(limit=50)
                queue_status = task_manager.get_queue_status()

                # å‡†å¤‡è¦å‘é€çš„æ•°æ®
                current_tasks_data = json.dumps(tasks, default=str)
                current_queue_data = json.dumps(queue_status)

                # æ£€æŸ¥æ•°æ®æ˜¯å¦æœ‰å˜åŒ–
                if (
                    current_tasks_data != last_tasks_data
                    or current_queue_data != last_queue_data
                ):
                    # å‘é€åˆå¹¶çš„æ•°æ®
                    combined_data = {"tasks": tasks, "queue_status": queue_status}
                    # ä½¿ç”¨ default=str æ¥å¤„ç† ObjectId å’Œ datetime å¯¹è±¡
                    json_data = json.dumps(combined_data, default=str)
                    yield f"data: {json_data}\n\n"

                    # æ›´æ–°æœ€åçš„æ•°æ®çŠ¶æ€
                    last_tasks_data = current_tasks_data
                    last_queue_data = current_queue_data

            except Exception as e:
                logging.error(f"Error in SSE task stream: {e}", exc_info=True)
                # å¦‚æœå‘ç”Ÿé”™è¯¯ï¼Œå¯ä»¥å‘é€ä¸€ä¸ªé”™è¯¯äº‹ä»¶
                error_data = json.dumps({"error": "An internal error occurred"})
                yield f"event: error\ndata: {error_data}\n\n"

            # ç­‰å¾…30ç§’å†æ£€æŸ¥
            time.sleep(30)

    return Response(event_stream(), mimetype="text/event-stream")


@admin_bp.route("/api/pdf/task-stream/<task_id>")
@admin_required
def task_detail_stream(task_id):
    """ä½¿ç”¨SSEæ¨é€å•ä¸ªä»»åŠ¡çš„è¯¦ç»†æ›´æ–°"""

    def event_stream():
        last_task_data = None
        while True:
            try:
                task = task_manager.get_task_status(task_id)
                if not task:
                    error_data = json.dumps({"error": "Task not found"})
                    yield f"event: error\ndata: {error_data}\n\n"
                    break

                current_task_data = json.dumps(task, default=str)

                if current_task_data != last_task_data:
                    # æ ¼å¼åŒ–æ—¶é—´æˆ³ä»¥ä¾¿JSå¯ä»¥ç›´æ¥ä½¿ç”¨
                    if "created_at" in task and hasattr(task["created_at"], "strftime"):
                        task["created_at_str"] = task["created_at"].strftime(
                            "%Y-%m-%d %H:%M:%S"
                        )
                    if "updated_at" in task and hasattr(task["updated_at"], "strftime"):
                        task["updated_at_str"] = task["updated_at"].strftime(
                            "%Y-%m-%d %H:%M:%S"
                        )
                    if "logs" in task:
                        for log in task["logs"]:
                            if "timestamp" in log and hasattr(
                                log["timestamp"], "strftime"
                            ):
                                log["timestamp_str"] = log["timestamp"].strftime(
                                    "%H:%M:%S"
                                )

                    json_data = json.dumps(task, default=str)
                    yield f"data: {json_data}\n\n"
                    last_task_data = current_task_data

                # å¦‚æœä»»åŠ¡å®Œæˆæˆ–å¤±è´¥ï¼Œåˆ™åœæ­¢å‘é€
                if task.get("status") in ["completed", "failed"]:
                    break

            except Exception as e:
                logging.error(
                    f"Error in SSE task detail stream for task {task_id}: {e}",
                    exc_info=True,
                )
                error_data = json.dumps({"error": "An internal error occurred"})
                yield f"event: error\ndata: {error_data}\n\n"
                break

            time.sleep(30)

    return Response(event_stream(), mimetype="text/event-stream")


@admin_bp.route("/api/pdf/task/<task_id>/restart", methods=["POST"])
@admin_required
def restart_task(task_id):
    """ä»æŒ‡å®šæ­¥éª¤é‡å¯ä»»åŠ¡"""
    try:
        data = request.get_json()

        if not data or "step_name" not in data:
            return jsonify({"error": "ç¼ºå°‘æ­¥éª¤åç§°å‚æ•°"}), 400

        step_name = data["step_name"]

        # éªŒè¯æ­¥éª¤åç§°
        valid_steps = [
            "01_pdf2img",
            "02_ocr",
            "03_translate",
            "04_analysis",
            "05_output",
        ]
        if step_name not in valid_steps:
            return jsonify({"error": f"æ— æ•ˆçš„æ­¥éª¤åç§°ï¼Œæœ‰æ•ˆæ­¥éª¤: {valid_steps}"}), 400

        success = task_manager.restart_task_from_step(task_id, step_name)

        if success:
            return jsonify({"message": f"ä»»åŠ¡å·²è®¾ç½®ä¸ºä»æ­¥éª¤ {step_name} é‡å¯"})
        else:
            return jsonify({"error": "é‡å¯ä»»åŠ¡å¤±è´¥"}), 500

    except Exception as e:
        logging.error(f"[Admin API] é‡å¯ä»»åŠ¡å¤±è´¥: {e}", exc_info=True)
        return jsonify({"error": "æœåŠ¡å™¨å†…éƒ¨é”™è¯¯"}), 500


@admin_bp.route("/api/pdf/task/<task_id>/start", methods=["POST"])
@admin_required
def start_pending_task(task_id):
    """æ‰‹åŠ¨å¯åŠ¨å¾…å¤„ç†çš„ä»»åŠ¡"""
    try:
        success = task_manager.start_pending_task(task_id)

        if success:
            return jsonify({"message": "ä»»åŠ¡å·²æ·»åŠ åˆ°å¤„ç†é˜Ÿåˆ—"})
        else:
            return jsonify({"error": "å¯åŠ¨ä»»åŠ¡å¤±è´¥"}), 500

    except Exception as e:
        logging.error(f"[Admin API] å¯åŠ¨ä»»åŠ¡å¤±è´¥: {e}", exc_info=True)
        return jsonify({"error": "æœåŠ¡å™¨å†…éƒ¨é”™è¯¯"}), 500


@admin_bp.route("/api/pdf/queue/process", methods=["POST"])
@admin_required
def process_queue():
    """æ‰‹åŠ¨è§¦å‘é˜Ÿåˆ—å¤„ç†"""
    try:
        # æ¢å¤å¾…å¤„ç†ä»»åŠ¡åˆ°é˜Ÿåˆ—
        task_manager.recover_pending_tasks()

        # å¤„ç†é˜Ÿåˆ—
        task_manager.process_queue()

        # è·å–é˜Ÿåˆ—çŠ¶æ€
        queue_status = task_manager.get_queue_status()

        return jsonify({"message": "é˜Ÿåˆ—å¤„ç†å·²è§¦å‘", "queue_status": queue_status})

    except Exception as e:
        logging.error(f"[Admin API] æ‰‹åŠ¨å¤„ç†é˜Ÿåˆ—å¤±è´¥: {e}", exc_info=True)
        return jsonify({"error": "æœåŠ¡å™¨å†…éƒ¨é”™è¯¯"}), 500
