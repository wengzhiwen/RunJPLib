from datetime import datetime
from datetime import timedelta
from functools import wraps
import json
import logging
import os
import tempfile
import time
import uuid

from bson.objectid import ObjectId
from flask import Blueprint
from flask import jsonify
from flask import make_response
from flask import redirect
from flask import render_template
from flask import request
from flask import Response
from flask import url_for
from flask_jwt_extended import create_access_token
from flask_jwt_extended import get_jwt_identity
from flask_jwt_extended import set_access_cookies
from flask_jwt_extended import unset_jwt_cookies
from flask_jwt_extended import verify_jwt_in_request
from werkzeug.utils import secure_filename

from utils.blog_generator import BlogGenerator
from utils.chat_logging import chat_logger
from utils.mongo_client import get_db
from utils.mongo_client import get_mongo_client
from utils.task_manager import task_manager
from utils.thread_pool_manager import thread_pool_manager

admin_bp = Blueprint("admin", __name__, url_prefix="/admin", template_folder="../templates/admin")

PROJECT_ROOT = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))

# --- åå°ç®¡ç†æ•°æ®åº“æ“ä½œè¾…åŠ©å‡½æ•° ---


def _update_university_in_db(object_id, update_data, university_id):
    """å¼‚æ­¥æ›´æ–°å¤§å­¦ä¿¡æ¯åˆ°æ•°æ®åº“"""
    try:
        db = get_db()
        if db is None:
            logging.error("Adminå¼‚æ­¥æ›´æ–°å¤§å­¦ä¿¡æ¯å¤±è´¥ï¼šæ— æ³•è¿æ¥æ•°æ®åº“")
            return
        db.universities.update_one({"_id": object_id}, update_data)
        logging.info(f"University with ID {university_id} was updated (async).")
    except Exception as e:
        logging.error(f"å¼‚æ­¥æ›´æ–°å¤§å­¦ä¿¡æ¯å¤±è´¥: {e}")


def _save_blog_to_db(blog_data):
    """å¼‚æ­¥ä¿å­˜åšå®¢åˆ°æ•°æ®åº“"""
    try:
        db = get_db()
        if db is None:
            logging.error("Adminå¼‚æ­¥ä¿å­˜åšå®¢å¤±è´¥ï¼šæ— æ³•è¿æ¥æ•°æ®åº“")
            return None

        # åº”ç”¨WikiåŠŸèƒ½ï¼šè‡ªåŠ¨è¯†åˆ«å­¦æ ¡åç§°å¹¶æ·»åŠ è¶…é“¾æ¥
        from utils.blog_wiki_processor import blog_wiki_processor
        original_content = blog_data.get('content_md', '')
        processed_content = blog_wiki_processor.process_blog_content(original_content)

        # å¦‚æœå†…å®¹è¢«å¤„ç†äº†ï¼Œæ›´æ–°blog_data
        if processed_content != original_content:
            blog_data['content_md'] = processed_content
            logging.info("Blogå†…å®¹å·²åº”ç”¨WikiåŠŸèƒ½ï¼Œè‡ªåŠ¨æ·»åŠ äº†å­¦æ ¡åç§°è¶…é“¾æ¥")

        result = db.blogs.insert_one(blog_data)
        logging.info(f"New blog post created with ID: {result.inserted_id} (async).")

        # æ¸…é™¤æ¨èåšå®¢ç¼“å­˜ï¼Œç¡®ä¿æ–°åšå®¢èƒ½åŠæ—¶å‡ºç°åœ¨æ¨èä¸­
        from routes.blog import clear_recommended_blogs_cache
        clear_recommended_blogs_cache()

        return str(result.inserted_id)
    except Exception as e:
        logging.error(f"å¼‚æ­¥ä¿å­˜åšå®¢å¤±è´¥: {e}")
        return None


def _update_blog_in_db(object_id, update_data, blog_id):
    """å¼‚æ­¥æ›´æ–°åšå®¢åˆ°æ•°æ®åº“"""
    try:
        db = get_db()
        if db is None:
            logging.error("Adminå¼‚æ­¥æ›´æ–°åšå®¢å¤±è´¥ï¼šæ— æ³•è¿æ¥æ•°æ®åº“")
            return

        # åº”ç”¨WikiåŠŸèƒ½ï¼šè‡ªåŠ¨è¯†åˆ«å­¦æ ¡åç§°å¹¶æ·»åŠ è¶…é“¾æ¥
        if 'content_md' in update_data['$set']:
            from utils.blog_wiki_processor import blog_wiki_processor
            original_content = update_data['$set']['content_md']
            processed_content = blog_wiki_processor.process_blog_content(original_content)

            # å¦‚æœå†…å®¹è¢«å¤„ç†äº†ï¼Œæ›´æ–°update_data
            if processed_content != original_content:
                update_data['$set']['content_md'] = processed_content
                logging.info("Blogå†…å®¹å·²åº”ç”¨WikiåŠŸèƒ½ï¼Œè‡ªåŠ¨æ·»åŠ äº†å­¦æ ¡åç§°è¶…é“¾æ¥")

        db.blogs.update_one({"_id": object_id}, update_data)
        logging.info(f"Blog post with ID {blog_id} was updated (async).")

        # æ¸…é™¤æ¨èåšå®¢ç¼“å­˜ï¼Œç¡®ä¿æ›´æ–°çš„åšå®¢èƒ½åŠæ—¶åæ˜ åœ¨æ¨èä¸­
        from routes.blog import clear_recommended_blogs_cache
        clear_recommended_blogs_cache()
    except Exception as e:
        logging.error(f"å¼‚æ­¥æ›´æ–°åšå®¢å¤±è´¥: {e}")


def admin_required(fn):
    """ç®¡ç†å‘˜æƒé™éªŒè¯è£…é¥°å™¨"""

    @wraps(fn)
    def wrapper(*args, **kwargs):
        is_api_request = request.path.startswith("/admin/api/")
        try:
            verify_jwt_in_request(locations=["headers", "cookies"])
            identity = get_jwt_identity()
            if identity != "admin":
                logging.warning("A non-admin identity was found in a valid JWT.")
                if is_api_request:
                    return jsonify(msg="éœ€è¦ç®¡ç†å‘˜æƒé™"), 403
                else:
                    return redirect(url_for("admin.login"))
        except Exception as e:
            logging.warning(f"JWT validation failed for path '{request.path}': {e}")
            if is_api_request:
                return jsonify(msg="Tokenæ— æ•ˆæˆ–å·²è¿‡æœŸ"), 401
            else:
                return redirect(url_for("admin.login"))
        return fn(*args, **kwargs)

    return wrapper


def _get_dashboard_stats():
    """è·å–ä»ªè¡¨ç›˜æ ¸å¿ƒç»Ÿè®¡æ•°æ®çš„è¾…åŠ©å‡½æ•°"""
    db = get_db()
    if db is None:
        logging.error("ä»ªè¡¨ç›˜æ— æ³•è¿æ¥åˆ°æ•°æ®åº“")
        return {"error": "æ•°æ®åº“è¿æ¥å¤±è´¥"}
    stats = {}
    try:
        stats["university_count"] = db.universities.count_documents({})
        stats["blog_count"] = db.blogs.count_documents({})
        twenty_four_hours_ago = datetime.utcnow() - timedelta(hours=24)
        query_24h = {"timestamp": {"$gte": twenty_four_hours_ago}}

        # è®¿é—®æ—¥å¿—ç»Ÿè®¡
        unique_ips = db.access_logs.distinct("ip", query_24h)
        stats["unique_ip_count_24h"] = len(unique_ips)
        query_uni_24h = {
            "timestamp": {
                "$gte": twenty_four_hours_ago
            },
            "page_type": "university",
        }
        stats["university_views_24h"] = db.access_logs.count_documents(query_uni_24h)
        query_blog_24h = {
            "timestamp": {
                "$gte": twenty_four_hours_ago
            },
            "page_type": "blog",
        }
        stats["blog_views_24h"] = db.access_logs.count_documents(query_blog_24h)

        # å¯¹è¯åŠŸèƒ½ç»Ÿè®¡
        chat_query_24h = {"last_activity": {"$gte": twenty_four_hours_ago}}
        stats["chat_count_24h"] = db.chat_sessions.count_documents(chat_query_24h)
        unique_chat_ips = db.chat_sessions.distinct("user_ip", chat_query_24h)
        stats["unique_chat_ip_count_24h"] = len(unique_chat_ips)

    except Exception as e:
        logging.error(f"æŸ¥è¯¢ä»ªè¡¨ç›˜ç»Ÿè®¡æ•°æ®æ—¶å‡ºé”™: {e}", exc_info=True)
        return {"error": "æŸ¥è¯¢ç»Ÿè®¡æ•°æ®æ—¶å‡ºé”™"}
    return stats


@admin_bp.route("/")
@admin_required
def dashboard():
    """ä»ªè¡¨ç›˜è·¯ç”±ï¼Œå±•ç¤ºç»Ÿè®¡æ•°æ®"""
    stats = _get_dashboard_stats()
    if "error" in stats:
        return render_template("dashboard.html", error=stats["error"])

    client = get_mongo_client()
    expired_premium_universities = []
    if client is not None:

        try:
            today = datetime.utcnow().replace(hour=0, minute=0, second=0, microsecond=0)
            pipeline = [
                {
                    "$group": {
                        "_id": "$university_name",
                        "max_deadline": {
                            "$max": "$deadline"
                        },
                        "has_premium": {
                            "$max": "$is_premium"
                        },
                    }
                },
                {
                    "$match": {
                        "has_premium": True,
                        "max_deadline": {
                            "$lt": today
                        }
                    }
                },
                {
                    "$sort": {
                        "max_deadline": 1
                    }
                },
                {
                    "$project": {
                        "_id": 0,
                        "university_name": "$_id",
                        "deadline": "$max_deadline",
                    }
                },
            ]
            expired_premium_universities = list(client.RunJPLib.universities.aggregate(pipeline))
        except Exception as e:
            logging.error(f"æŸ¥è¯¢è¿‡æœŸPremiumå­¦æ ¡æ—¶å‡ºé”™: {e}", exc_info=True)

    return render_template(
        "dashboard.html",
        stats=stats,
        expired_premium_universities=expired_premium_universities,
    )


@admin_bp.route("/login")
def login():
    return render_template("login.html")


@admin_bp.route("/logout")
def logout():
    response = make_response(redirect(url_for("admin.login")))
    unset_jwt_cookies(response)
    return response


@admin_bp.route("/api/login", methods=["POST"])
def api_login():
    data = request.get_json()
    if not data:
        logging.error("ç™»å½•å¤±è´¥: è¯·æ±‚ä½“ä¸æ˜¯æœ‰æ•ˆçš„JSONæˆ–Content-Typeå¤´ç¼ºå¤±ã€‚")
        return jsonify({"msg": "æ— æ•ˆçš„è¯·æ±‚æ ¼å¼"}), 400
    access_code = data.get("access_code")
    env_access_code = os.getenv("ACCESS_CODE")
    if not env_access_code:
        logging.error("ä¸¥é‡å®‰å…¨é…ç½®é”™è¯¯: ç¯å¢ƒå˜é‡ ACCESS_CODE æœªè®¾ç½®ã€‚")
        return jsonify({"msg": "æœåŠ¡å™¨é…ç½®é”™è¯¯"}), 500
    if not access_code or access_code != env_access_code:
        logging.warning("æ”¶åˆ°ä¸€ä¸ªé”™è¯¯çš„è®¿é—®ç ã€‚")
        return jsonify({"msg": "è®¿é—®ç é”™è¯¯"}), 401
    logging.info("ç®¡ç†å‘˜ç™»å½•æˆåŠŸã€‚")
    access_token = create_access_token(identity="admin")
    response = jsonify(msg="ç™»å½•æˆåŠŸ")
    set_access_cookies(response, access_token)
    return response


@admin_bp.route("/api/verify_token")
@admin_required
def verify_token():
    return jsonify(status="ok")


# --- èŠå¤©è®°å½•ç®¡ç†API ---


@admin_bp.route("/chat-logs")
@admin_required
def chat_logs_page():
    """èŠå¤©è®°å½•ç®¡ç†é¡µé¢"""
    db = get_db()
    if db is None:
        return render_template("chat_logs.html", error="æ•°æ®åº“è¿æ¥å¤±è´¥", sessions=[])

    try:
        # æŸ¥è¯¢æ‰€æœ‰ä¼šè¯ï¼ŒæŒ‰æœ€åæ´»åŠ¨æ—¶é—´æ’åº
        sessions = list(db.chat_sessions.find().sort("last_activity", -1))

        # è½¬æ¢æ•°æ®æ ¼å¼ä»¥åŒ¹é…æ¨¡æ¿æœŸæœ›
        formatted_sessions = []
        for session in sessions:
            formatted_sessions.append({
                "_id": session["session_id"],  # ä½¿ç”¨session_idä½œä¸º_id
                "session_id": session["session_id"],
                "last_activity": session["last_activity"],
                "ip_address": session["user_ip"],
                "message_count": session["total_messages"],
                "university_name": session.get("university_name", "æœªçŸ¥"),
                "user_agent": session.get("user_agent", "")
            })

        return render_template("chat_logs.html", sessions=formatted_sessions)
    except Exception as e:
        logging.error(f"è·å–èŠå¤©ä¼šè¯åˆ—è¡¨å¤±è´¥: {e}", exc_info=True)
        return render_template("chat_logs.html", error="æŸ¥è¯¢ä¼šè¯åˆ—è¡¨å¤±è´¥", sessions=[])


@admin_bp.route("/chat_log/<session_id>")
@admin_required
def chat_log_detail(session_id):
    """æ˜¾ç¤ºç‰¹å®šä¼šè¯çš„èŠå¤©è®°å½•"""
    db = get_db()
    if db is None:
        return render_template("chat_log_detail.html", error="æ•°æ®åº“è¿æ¥å¤±è´¥", logs=[])

    try:
        # æŸ¥è¯¢ç‰¹å®šä¼šè¯
        session = db.chat_sessions.find_one({"session_id": session_id})
        if not session:
            return render_template("chat_log_detail.html", error="ä¼šè¯ä¸å­˜åœ¨", logs=[])

        # è·å–ä¼šè¯ä¸­çš„æ¶ˆæ¯
        messages = session.get("messages", [])

        # è½¬æ¢æ¶ˆæ¯æ ¼å¼ä»¥åŒ¹é…æ¨¡æ¿æœŸæœ›
        formatted_logs = []
        for msg in messages:
            formatted_logs.append({
                "timestamp": msg.get("timestamp"),
                "message": msg.get("user_input", ""),
                "response": msg.get("ai_response", ""),
                "processing_time": msg.get("processing_time", 0)
            })

        return render_template("chat_log_detail.html", logs=formatted_logs, session_id=session_id)
    except Exception as e:
        logging.error(f"è·å–ä¼šè¯ {session_id} çš„èŠå¤©è®°å½•å¤±è´¥: {e}", exc_info=True)
        return render_template("chat_log_detail.html", error="æŸ¥è¯¢èŠå¤©è®°å½•å¤±è´¥", logs=[])


@admin_bp.route("/api/chat-sessions", methods=["GET"])
@admin_required
def get_chat_sessions():
    """è·å–èŠå¤©ä¼šè¯åˆ—è¡¨"""
    try:
        skip = int(request.args.get("skip", 0))
        limit = int(request.args.get("limit", 20))
        start_date = request.args.get("start_date")
        end_date = request.args.get("end_date")
        university = request.args.get("university")
        user_ip = request.args.get("user_ip")

        # æ„å»ºæŸ¥è¯¢æ¡ä»¶
        query = {}
        if start_date:
            query["start_time"] = {"$gte": datetime.fromisoformat(start_date)}
        if end_date:
            end_datetime = datetime.fromisoformat(end_date)
            if "start_time" in query:
                query["start_time"]["$lte"] = end_datetime
            else:
                query["start_time"] = {"$lte": end_datetime}
        if university:
            query["university_name"] = university
        if user_ip:
            query["user_ip"] = {"$regex": user_ip, "$options": "i"}

        # è·å–ä¼šè¯åˆ—è¡¨
        db = get_db()
        if db is None:
            return jsonify({"success": False, "error": "æ•°æ®åº“è¿æ¥å¤±è´¥"}), 500

        sessions = list(
            db.chat_sessions.find(query, {
                "session_id": 1,
                "user_ip": 1,
                "university_name": 1,
                "start_time": 1,
                "last_activity": 1,
                "total_messages": 1
            }).sort("start_time", -1).skip(skip).limit(limit))

        # è·å–æ€»æ•°
        total = db.chat_sessions.count_documents(query)

        # è½¬æ¢ObjectIdä¸ºå­—ç¬¦ä¸²
        for session in sessions:
            session["_id"] = str(session["_id"])

        return jsonify({"success": True, "sessions": sessions, "total": total})

    except Exception as e:
        logging.error(f"è·å–èŠå¤©ä¼šè¯åˆ—è¡¨å¤±è´¥: {e}", exc_info=True)
        return jsonify({"success": False, "error": str(e)}), 500


@admin_bp.route("/api/chat-sessions/<session_id>", methods=["GET"])
@admin_required
def get_chat_session_detail(session_id):
    """è·å–èŠå¤©ä¼šè¯è¯¦æƒ…"""
    try:
        session = chat_logger.get_chat_session_detail(session_id)

        if session:
            return jsonify({"success": True, "session": session})
        else:
            return jsonify({"success": False, "error": "ä¼šè¯ä¸å­˜åœ¨"}), 404

    except Exception as e:
        logging.error(f"è·å–èŠå¤©ä¼šè¯è¯¦æƒ…å¤±è´¥: {e}", exc_info=True)
        return jsonify({"success": False, "error": str(e)}), 500


@admin_bp.route("/api/chat-statistics", methods=["GET"])
@admin_required
def get_chat_statistics():
    """è·å–èŠå¤©ç»Ÿè®¡ä¿¡æ¯"""
    try:
        statistics = chat_logger.get_chat_statistics()

        return jsonify({"success": True, "statistics": statistics})

    except Exception as e:
        logging.error(f"è·å–èŠå¤©ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}", exc_info=True)
        return jsonify({"success": False, "error": str(e)}), 500


@admin_bp.route("/api/chat-universities", methods=["GET"])
@admin_required
def get_chat_universities():
    """è·å–èŠå¤©æ¶‰åŠçš„å¤§å­¦åˆ—è¡¨"""
    try:
        db = get_db()
        if db is None:
            return jsonify({"success": False, "error": "æ•°æ®åº“è¿æ¥å¤±è´¥"}), 500

        universities = db.chat_sessions.distinct("university_name")
        universities = [uni for uni in universities if uni]  # è¿‡æ»¤ç©ºå€¼

        return jsonify({"success": True, "universities": sorted(universities)})

    except Exception as e:
        logging.error(f"è·å–èŠå¤©å¤§å­¦åˆ—è¡¨å¤±è´¥: {e}", exc_info=True)
        return jsonify({"success": False, "error": str(e)}), 500


@admin_bp.route("/api/chat-cleanup", methods=["POST"])
@admin_required
def cleanup_chat_sessions():
    """æ¸…ç†æ—§çš„èŠå¤©ä¼šè¯"""
    try:
        data = request.get_json()
        days = data.get("days", 90) if data else 90

        deleted_count = chat_logger.cleanup_old_sessions(days)

        return jsonify({"success": True, "deleted_count": deleted_count, "message": f"å·²æ¸…ç† {deleted_count} ä¸ªè¶…è¿‡ {days} å¤©çš„èŠå¤©ä¼šè¯"})

    except Exception as e:
        logging.error(f"æ¸…ç†èŠå¤©ä¼šè¯å¤±è´¥: {e}", exc_info=True)
        return jsonify({"success": False, "error": str(e)}), 500


# --- æ•°æ®ç®¡ç†é¡µé¢ ---
@admin_bp.route("/manage/universities")
@admin_required
def manage_universities_page():
    return render_template("manage_universities.html")


@admin_bp.route("/manage/blogs")
@admin_required
def manage_blogs_page():
    return render_template("manage_blogs.html")


# --- æ•°æ®ç®¡ç†API ---
@admin_bp.route("/api/universities", methods=["GET"])
@admin_required
def get_universities():
    db = get_db()
    if db is None:
        logging.error("[Admin API] Get universities failed: DB connection error.")
        return jsonify({"error": "æ•°æ®åº“è¿æ¥å¤±è´¥"}), 500

    try:
        logging.debug("[Admin API] Fetching universities from database...")
        projection = {"content": 0, "source_path": 0}
        # ä¼˜åŒ–æ’åºï¼šæŒ‰ _id é€†åºæ’åˆ—ï¼Œå®ç°æŒ‰åˆ›å»ºæ—¶é—´å€’åº
        cursor = db.universities.find({}, projection).sort("_id", -1)

        universities = list(cursor)

        for u in universities:
            u["_id"] = str(u["_id"])
            # ç¡®ä¿ deadline å­—æ®µæ˜¯ ISO æ ¼å¼çš„å­—ç¬¦ä¸²ï¼Œæ–¹ä¾¿å‰ç«¯è§£æ
            if u.get("deadline") and isinstance(u["deadline"], datetime):
                u["deadline"] = u["deadline"].isoformat()

        logging.info(f"[Admin API] Successfully fetched {len(universities)} university documents.")
        if universities:
            logging.debug(f"[Admin API] First university document sample: {universities[0]}")

        return jsonify(universities)
    except Exception as e:
        logging.error(
            f"[Admin API] An exception occurred while fetching universities: {e}",
            exc_info=True,
        )
        return jsonify({"error": "æœåŠ¡å™¨å†…éƒ¨é”™è¯¯"}), 500


@admin_bp.route("/edit_university/<university_id>", methods=["GET", "POST"])
@admin_required
def edit_university(university_id):
    """
    ç¼–è¾‘å¤§å­¦ä¿¡æ¯çš„é¡µé¢å’Œå¤„ç†é€»è¾‘
    GET: æ˜¾ç¤ºç¼–è¾‘è¡¨å•
    POST: æ›´æ–°å¤§å­¦ä¿¡æ¯
    """
    db = get_db()
    if db is None:
        return render_template("edit_university.html", error="æ•°æ®åº“è¿æ¥å¤±è´¥")

    try:
        object_id = ObjectId(university_id)
    except Exception:
        return render_template("404.html"), 404

    if request.method == "POST":
        university_name = request.form.get("university_name", "").strip()
        university_name_zh = request.form.get("university_name_zh", "").strip()
        is_premium = request.form.get("is_premium") == "true"
        deadline_str = request.form.get("deadline", "")
        basic_analysis_report = request.form.get("basic_analysis_report", "").strip()

        if not university_name:
            university = db.universities.find_one({"_id": object_id})
            return render_template("edit_university.html", university=university, error="å¤§å­¦åç§°ä¸èƒ½ä¸ºç©º")

        update_data = {
            "$set": {
                "university_name": university_name,
                "university_name_zh": university_name_zh,
                "is_premium": is_premium,
                "content.report_md": basic_analysis_report,
                "last_modified": datetime.utcnow(),
            }
        }

        if deadline_str:
            try:
                # å°† YYYY-MM-DD æ ¼å¼çš„å­—ç¬¦ä¸²è½¬æ¢ä¸º datetime å¯¹è±¡
                update_data["$set"]["deadline"] = datetime.strptime(deadline_str, "%Y-%m-%d")
            except ValueError:
                # å¦‚æœæ—¥æœŸæ ¼å¼ä¸æ­£ç¡®ï¼Œè¿”å›é”™è¯¯ä¿¡æ¯
                university = db.universities.find_one({"_id": object_id})
                return render_template(
                    "edit_university.html",
                    university=university,
                    error="æ—¥æœŸæ ¼å¼ä¸æ­£ç¡®ï¼Œè¯·ä½¿ç”¨ YYYY-MM-DD æ ¼å¼ã€‚",
                )

        # å°è¯•å¼‚æ­¥æ›´æ–°æ•°æ®åº“
        success = thread_pool_manager.submit_admin_task(_update_university_in_db, object_id, update_data, university_id)

        if not success:
            # çº¿ç¨‹æ± æ»¡ï¼ŒåŒæ­¥æ‰§è¡Œ
            logging.warning("Adminçº¿ç¨‹æ± ç¹å¿™ï¼ŒåŒæ­¥æ›´æ–°å¤§å­¦ä¿¡æ¯")
            try:
                db.universities.update_one({"_id": object_id}, update_data)
                logging.info(f"University with ID {university_id} was updated (sync).")
            except Exception as e:
                logging.error(f"åŒæ­¥æ›´æ–°å¤§å­¦ä¿¡æ¯å¤±è´¥: {e}")
                return render_template(
                    "edit_university.html",
                    university=db.universities.find_one({"_id": object_id}),
                    error="æ›´æ–°å¤±è´¥ï¼Œè¯·é‡è¯•",
                )
        else:
            logging.info(f"University with ID {university_id} update task submitted to thread pool.")

        return redirect(url_for("admin.manage_universities_page"))

    # GET è¯·æ±‚
    university = db.universities.find_one({"_id": object_id})
    if not university:
        return render_template("404.html"), 404

    return render_template("edit_university.html", university=university)


@admin_bp.route("/api/universities/<item_id>", methods=["DELETE"])
@admin_required
def delete_university(item_id):
    db = get_db()
    if db is None:
        return jsonify({"error": "æ•°æ®åº“è¿æ¥å¤±è´¥"}), 500

    db.universities.delete_one({"_id": ObjectId(item_id)})
    return jsonify({"message": "åˆ é™¤æˆåŠŸ"})


@admin_bp.route("/api/universities", methods=["DELETE"])
@admin_required
def clear_universities():
    db = get_db()
    if db is None:
        return jsonify({"error": "æ•°æ®åº“è¿æ¥å¤±è´¥"}), 500

    db.universities.delete_many({})
    return jsonify({"message": "æ•°æ®é›†åˆå·²æ¸…ç©º"})


@admin_bp.route("/api/blogs", methods=["GET"])
@admin_required
def get_blogs():
    db = get_db()
    if db is None:
        return jsonify({"error": "æ•°æ®åº“è¿æ¥å¤±è´¥"}), 500

    cursor = db.blogs.find({}).sort("publication_date", -1)
    blogs = []
    for b in cursor:
        b["_id"] = str(b["_id"])
        html_status = "æœªç”Ÿæˆ"
        md_last_updated = b.get("md_last_updated")
        html_last_updated = b.get("html_last_updated")
        if html_last_updated:
            html_status = "æœ€æ–°"
            if md_last_updated and md_last_updated > html_last_updated:
                html_status = "å¾…æ›´æ–°"
        b["html_status"] = html_status
        if md_last_updated:
            b["md_last_updated"] = md_last_updated.strftime("%Y-%m-%d %H:%M:%S")
        if html_last_updated:
            b["html_last_updated"] = html_last_updated.strftime("%Y-%m-%d %H:%M:%S")
        b.pop("content_md", None)
        b.pop("content_html", None)
        blogs.append(b)
    return jsonify(blogs)


@admin_bp.route("/api/blogs/<item_id>", methods=["DELETE"])
@admin_required
def delete_blog(item_id):
    db = get_db()
    if db is None:
        return jsonify({"error": "æ•°æ®åº“è¿æ¥å¤±è´¥"}), 500

    db.blogs.delete_one({"_id": ObjectId(item_id)})
    return jsonify({"message": "åˆ é™¤æˆåŠŸ"})


@admin_bp.route("/api/blogs", methods=["DELETE"])
@admin_required
def clear_blogs():
    db = get_db()
    if db is None:
        return jsonify({"error": "æ•°æ®åº“è¿æ¥å¤±è´¥"}), 500

    db.blogs.delete_many({})
    return jsonify({"message": "æ•°æ®é›†åˆå·²æ¸…ç©º"})


# --- åšå®¢åˆ›å»ºå·¥å…· ---


@admin_bp.route("/blog/create")
@admin_required
def create_blog_page():
    """æ¸²æŸ“åšå®¢åˆ›å»ºé¡µé¢"""
    return render_template("create_blog.html")


@admin_bp.route("/api/universities/search", methods=["GET"])
@admin_required
def search_universities():
    """
    æ ¹æ®åç§°æœç´¢å¤§å­¦ã€‚
    æ¥å—'q'ä½œä¸ºæŸ¥è¯¢å‚æ•°ã€‚
    """
    query = request.args.get("q", "").strip()
    if not query:
        return jsonify([])

    db = get_db()
    if db is None:
        return jsonify({"error": "æ•°æ®åº“è¿æ¥å¤±è´¥"}), 500

    try:
        # æ ¹æ®åç§°æ¨¡ç³Šæœç´¢ï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼‰
        universities = list(db.universities.find(
            {
                "university_name": {
                    "$regex": query,
                    "$options": "i"
                }
            },
            {
                "_id": 1,
                "university_name": 1
            },
        ).limit(20))  # é™åˆ¶20æ¡ç»“æœä»¥æé«˜æ€§èƒ½

        for u in universities:
            u["_id"] = str(u["_id"])

        return jsonify(universities)
    except Exception as e:
        logging.error(f"[Admin API] University search failed: {e}", exc_info=True)
        return jsonify({"error": "æœåŠ¡å™¨å†…éƒ¨é”™è¯¯"}), 500


@admin_bp.route("/api/blog/generate", methods=["POST"])
@admin_required
def generate_blog():
    """
    ä½¿ç”¨AIç”Ÿæˆåšå®¢å†…å®¹ã€‚
    éœ€è¦åŒ…å«'university_ids', 'user_prompt', 'system_prompt'çš„JSONã€‚
    """
    data = request.get_json()
    if not data:
        return jsonify({"error": "æ— æ•ˆçš„è¯·æ±‚æ ¼å¼"}), 400

    university_ids = data.get("university_ids", [])
    user_prompt = data.get("user_prompt", "")
    system_prompt = data.get("system_prompt", "")
    mode = data.get("mode", "expand")  # é»˜è®¤ä¸ºexpandæ¨¡å¼

    if not system_prompt:
        return jsonify({"error": "ç³»ç»Ÿæç¤ºè¯ä¸èƒ½ä¸ºç©º"}), 400

    # æ ¹æ®æ¨¡å¼éªŒè¯è¾“å…¥
    if mode in ["expand", "compare"] and not university_ids:
        return jsonify({"error": "è¯¥æ¨¡å¼éœ€è¦è‡³å°‘é€‰æ‹©ä¸€æ‰€å¤§å­¦"}), 400
    if mode == "compare" and len(university_ids) < 2:
        return jsonify({"error": "å¯¹æ¯”åˆ†ææ¨¡å¼éœ€è¦è‡³å°‘é€‰æ‹©ä¸¤æ‰€å¤§å­¦"}), 400
    if mode == "user_prompt_only" and not user_prompt:
        return jsonify({"error": "è¯¥æ¨¡å¼éœ€è¦å¡«å†™ç”¨æˆ·æç¤ºè¯"}), 400

    try:
        generator = BlogGenerator()
        result = generator.generate_blog_content(mode, university_ids, user_prompt, system_prompt)
        if result:
            return jsonify(result)
        else:
            return jsonify({"error": "ç”Ÿæˆæ–‡ç« å¤±è´¥"}), 500
    except Exception as e:
        logging.error(f"[Admin API] Blog generation failed: {e}", exc_info=True)
        return jsonify({"error": "æœåŠ¡å™¨å†…éƒ¨é”™è¯¯"}), 500


@admin_bp.route("/api/blog/save", methods=["POST"])
@admin_required
def save_blog():
    """
    ä¿å­˜æ–°åšå®¢æ–‡ç« åˆ°æ•°æ®åº“ã€‚
    éœ€è¦åŒ…å«'title'å’Œ'content_md'çš„JSONã€‚
    """
    data = request.get_json()
    if not data or "title" not in data or "content_md" not in data:
        return jsonify({"error": "æ— æ•ˆçš„è¯·æ±‚æ ¼å¼ï¼Œéœ€è¦'title'å’Œ'content_md'"}), 400

    title = data["title"].strip()
    content_md = data["content_md"].strip()

    if not title or not content_md:
        return jsonify({"error": "æ ‡é¢˜å’Œå†…å®¹ä¸èƒ½ä¸ºç©º"}), 400

    db = get_db()
    if db is None:
        return jsonify({"error": "æ•°æ®åº“è¿æ¥å¤±è´¥"}), 500

    try:
        # åˆ›å»ºURLå‹å¥½æ ‡é¢˜
        url_title = title.lower().replace(" ", "-").replace("/", "-")
        # ç§»é™¤ä¸å®‰å…¨çš„URLå­—ç¬¦
        url_title = "".join(c for c in url_title if c.isalnum() or c == "-")

        new_blog = {
            "title": title,
            "url_title": url_title,
            "publication_date": datetime.now().strftime("%Y-%m-%d"),
            "created_at": datetime.now(),
            "md_last_updated": datetime.now(),
            "html_last_updated": None,
            "content_md": content_md,
            "content_html": None,
        }

        # å°è¯•å¼‚æ­¥ä¿å­˜åšå®¢
        success = thread_pool_manager.submit_admin_task(_save_blog_to_db, new_blog)

        if not success:
            # çº¿ç¨‹æ± æ»¡ï¼ŒåŒæ­¥æ‰§è¡Œ
            logging.warning("Adminçº¿ç¨‹æ± ç¹å¿™ï¼ŒåŒæ­¥ä¿å­˜åšå®¢")
            try:
                # åº”ç”¨WikiåŠŸèƒ½
                from utils.blog_wiki_processor import blog_wiki_processor
                original_content = new_blog.get('content_md', '')
                processed_content = blog_wiki_processor.process_blog_content(original_content)

                if processed_content != original_content:
                    new_blog['content_md'] = processed_content
                    logging.info("Blogå†…å®¹å·²åº”ç”¨WikiåŠŸèƒ½ï¼Œè‡ªåŠ¨æ·»åŠ äº†å­¦æ ¡åç§°è¶…é“¾æ¥")

                result = db.blogs.insert_one(new_blog)
                logging.info(f"New blog post created with ID: {result.inserted_id} (sync).")

                # æ¸…é™¤æ¨èåšå®¢ç¼“å­˜ï¼Œç¡®ä¿æ–°åšå®¢èƒ½åŠæ—¶å‡ºç°åœ¨æ¨èä¸­
                from routes.blog import clear_recommended_blogs_cache
                clear_recommended_blogs_cache()

                return jsonify({"message": "æ–‡ç« ä¿å­˜æˆåŠŸ", "blog_id": str(result.inserted_id)})
            except Exception as sync_e:
                logging.error(f"åŒæ­¥ä¿å­˜åšå®¢å¤±è´¥: {sync_e}")
                return jsonify({"error": "ä¿å­˜å¤±è´¥ï¼Œè¯·é‡è¯•"}), 500
        else:
            # å¼‚æ­¥ä»»åŠ¡å·²æäº¤
            logging.info("Blog save task submitted to thread pool.")
            return jsonify({"message": "æ–‡ç« ä¿å­˜ä»»åŠ¡å·²æäº¤", "blog_id": "pending"})
    except Exception as e:
        logging.error(f"[Admin API] Failed to save blog: {e}", exc_info=True)
        return jsonify({"error": "æœåŠ¡å™¨å†…éƒ¨é”™è¯¯"}), 500


@admin_bp.route("/blog/edit/<blog_id>", methods=["GET", "POST"])
@admin_required
def edit_blog(blog_id):
    """
    å¤„ç†åšå®¢æ–‡ç« ç¼–è¾‘ã€‚
    GET: æ˜¾ç¤ºç¼–è¾‘è¡¨å•ã€‚
    POST: æ›´æ–°æ•°æ®åº“ä¸­çš„æ–‡ç« ã€‚
    """
    db = get_db()
    if db is None:
        return render_template("edit_blog.html", error="æ•°æ®åº“è¿æ¥å¤±è´¥")

    try:
        object_id = ObjectId(blog_id)
    except Exception:
        return render_template("404.html"), 404

    if request.method == "POST":
        title = request.form.get("title", "").strip()
        content_md = request.form.get("content_md", "").strip()

        if not title or not content_md:
            blog = db.blogs.find_one({"_id": object_id})
            return render_template("edit_blog.html", blog=blog, error="æ ‡é¢˜å’Œå†…å®¹ä¸èƒ½ä¸ºç©º")

        # åˆ›å»ºURLå‹å¥½æ ‡é¢˜
        url_title = title.lower().replace(" ", "-").replace("/", "-")
        url_title = "".join(c for c in url_title if c.isalnum() or c == "-")

        update_data = {
            "$set": {
                "title": title,
                "url_title": url_title,
                "content_md": content_md,
                "md_last_updated": datetime.now(),
            }
        }

        # å°è¯•å¼‚æ­¥æ›´æ–°åšå®¢
        success = thread_pool_manager.submit_admin_task(_update_blog_in_db, object_id, update_data, blog_id)

        if not success:
            # çº¿ç¨‹æ± æ»¡ï¼ŒåŒæ­¥æ‰§è¡Œ
            logging.warning("Adminçº¿ç¨‹æ± ç¹å¿™ï¼ŒåŒæ­¥æ›´æ–°åšå®¢")
            try:
                # åº”ç”¨WikiåŠŸèƒ½
                if 'content_md' in update_data['$set']:
                    from utils.blog_wiki_processor import blog_wiki_processor
                    original_content = update_data['$set']['content_md']
                    processed_content = blog_wiki_processor.process_blog_content(original_content)

                    if processed_content != original_content:
                        update_data['$set']['content_md'] = processed_content
                        logging.info("Blogå†…å®¹å·²åº”ç”¨WikiåŠŸèƒ½ï¼Œè‡ªåŠ¨æ·»åŠ äº†å­¦æ ¡åç§°è¶…é“¾æ¥")

                db.blogs.update_one({"_id": object_id}, update_data)
                logging.info(f"Blog post with ID {blog_id} was updated (sync).")

                # æ¸…é™¤æ¨èåšå®¢ç¼“å­˜ï¼Œç¡®ä¿æ›´æ–°çš„åšå®¢èƒ½åŠæ—¶åæ˜ åœ¨æ¨èä¸­
                from routes.blog import clear_recommended_blogs_cache
                clear_recommended_blogs_cache()
            except Exception as e:
                logging.error(f"åŒæ­¥æ›´æ–°åšå®¢å¤±è´¥: {e}")
                return render_template(
                    "edit_blog.html",
                    blog=db.blogs.find_one({"_id": object_id}),
                    error="æ›´æ–°å¤±è´¥ï¼Œè¯·é‡è¯•",
                )
        else:
            logging.info(f"Blog post with ID {blog_id} update task submitted to thread pool.")

        return redirect(url_for("admin.manage_blogs_page"))

    # GETè¯·æ±‚
    blog = db.blogs.find_one({"_id": object_id})
    if not blog:
        return render_template("404.html"), 404

    blog["_id"] = str(blog["_id"])

    return render_template("edit_blog.html", blog=blog)


# --- PDFå¤„ç†é¡µé¢ ---
@admin_bp.route("/pdf/processor")
@admin_required
def pdf_processor_page():
    """PDFå¤„ç†å™¨é¡µé¢"""
    return render_template("pdf_processor.html")


@admin_bp.route("/pdf/tasks")
@admin_required
def pdf_tasks_page():
    """PDFä»»åŠ¡åˆ—è¡¨é¡µé¢"""
    return render_template("pdf_tasks.html")


@admin_bp.route("/pdf/task/<task_id>")
@admin_required
def pdf_task_detail_page(task_id):
    """PDFä»»åŠ¡è¯¦æƒ…é¡µé¢"""
    task = task_manager.get_task_status(task_id)
    if not task:
        return render_template("404.html"), 404
    return render_template("pdf_task_detail.html", task=task)


# --- åˆ†æï¼šæœ€è¿‘24å°æ—¶ç‹¬ç«‹IP ---
@admin_bp.route("/analytics/unique_ips")
@admin_required
def unique_ips_page():
    """å±•ç¤ºæœ€è¿‘24å°æ—¶çš„ç‹¬ç«‹IPåˆ—è¡¨åŠç›¸å…³ä¿¡æ¯ï¼ˆæ— SSEï¼‰ã€‚"""
    db = get_db()
    if db is None:
        return render_template("unique_ips.html", error="æ•°æ®åº“è¿æ¥å¤±è´¥", items=[])

    # ç¡®ä¿mmdbæ–‡ä»¶å¯ç”¨
    from utils.ip_geo import ip_geo_manager

    logging.info("ğŸ”§ æ£€æŸ¥mmdbæ–‡ä»¶å¯ç”¨æ€§...")
    mmdb_available = ip_geo_manager.ensure_mmdb_available()
    logging.info(f"ğŸ“ mmdbæ–‡ä»¶çŠ¶æ€: {'å¯ç”¨' if mmdb_available else 'ä¸å¯ç”¨'}")

    twenty_four_hours_ago = datetime.utcnow() - timedelta(hours=24)
    logging.info(f"â° æŸ¥è¯¢æ—¶é—´èŒƒå›´: {twenty_four_hours_ago} è‡³ä»Š")

    try:
        pipeline = [
            {
                "$match": {
                    "timestamp": {
                        "$gte": twenty_four_hours_ago
                    }
                }
            },
            {
                "$group": {
                    "_id": "$ip",
                    "first_seen": {
                        "$min": "$timestamp"
                    },
                    "last_seen": {
                        "$max": "$timestamp"
                    },
                    "visit_count": {
                        "$sum": 1
                    },
                    "page_types": {
                        "$addToSet": "$page_type"
                    },
                }
            },
            {
                "$sort": {
                    "last_seen": -1
                }
            },
        ]

        logging.info("ğŸ” æ‰§è¡ŒMongoDBèšåˆæŸ¥è¯¢...")
        results = list(db.access_logs.aggregate(pipeline))
        logging.info(f"ğŸ“Š æŸ¥è¯¢åˆ° {len(results)} ä¸ªç‹¬ç«‹IP")

        items = []
        ips_to_lookup = []

        for r in results:
            ip = r.get("_id")

            # æ£€æŸ¥è¯¥IPæ˜¯å¦å·²æœ‰åœ°ç†ä¿¡æ¯
            geo_info = None
            if mmdb_available:
                # ä»è®¿é—®è®°å½•ä¸­æŸ¥æ‰¾
                sample_log = db.access_logs.find_one({"ip": ip, "geo_info": {"$exists": True}})
                if sample_log and sample_log.get("geo_info"):
                    geo_info = sample_log["geo_info"]
                    logging.debug(f"âœ… ä»è®¿é—®è®°å½•ä¸­æ‰¾åˆ°åœ°ç†ä¿¡æ¯: {ip} -> {geo_info.get('city', 'N/A')}")
                else:
                    ips_to_lookup.append(ip)
                    logging.debug(f"â“ IPéœ€è¦è§£æåœ°ç†ä¿¡æ¯: {ip}")

            item = {
                "ip": ip,
                "first_seen": r.get("first_seen"),
                "last_seen": r.get("last_seen"),
                "visit_count": r.get("visit_count", 0),
                "page_types": r.get("page_types", []),
                "geo_info": geo_info,
            }
            items.append(item)

        logging.info(f"ğŸ¯ å‡†å¤‡å¤„ç† {len(ips_to_lookup)} ä¸ªIPçš„åœ°ç†ä¿¡æ¯")

        # æ‰¹é‡æŸ¥è¯¢åœ°ç†ä¿¡æ¯å¹¶æ›´æ–°æ•°æ®åº“
        if mmdb_available and ips_to_lookup:
            _batch_update_geo_info(db, ips_to_lookup, items)
        else:
            logging.info("â­ï¸ è·³è¿‡åœ°ç†ä¿¡æ¯å¤„ç† (mmdbä¸å¯ç”¨æˆ–æ— IPéœ€è¦å¤„ç†)")

        logging.info(f"âœ… é¡µé¢æ¸²æŸ“å®Œæˆï¼Œå…± {len(items)} ä¸ªIP")
        return render_template("unique_ips.html", items=items, mmdb_available=mmdb_available)
    except Exception as e:
        logging.error(f"æŸ¥è¯¢ç‹¬ç«‹IPç»Ÿè®¡å¤±è´¥: {e}", exc_info=True)
        return render_template("unique_ips.html", error="æŸ¥è¯¢å¤±è´¥", items=[])


def _batch_update_geo_info(db, ips_to_lookup, items):
    """æ‰¹é‡æ›´æ–°IPåœ°ç†ä¿¡æ¯åˆ°æ•°æ®åº“ï¼ˆåµŒå…¥æ–¹æ¡ˆï¼‰"""
    from utils.ip_geo import ip_geo_manager

    try:
        logging.info(f"ğŸ” å¼€å§‹æ‰¹é‡æ›´æ–°åœ°ç†ä¿¡æ¯ï¼Œæ€»IPæ•°é‡: {len(ips_to_lookup)}")

        # é™åˆ¶æ‰¹é‡å¤„ç†æ•°é‡
        batch_size = 200
        processed_count = 0
        skipped_count = 0

        logging.info(f"âš™ï¸ æ‰¹é‡å¤„ç†é™åˆ¶: {batch_size} ä¸ªIP")

        for ip in ips_to_lookup:
            if processed_count >= batch_size:
                logging.info(f"â¹ï¸ è¾¾åˆ°æ‰¹é‡å¤„ç†é™åˆ¶ {batch_size}ï¼Œè·³è¿‡å‰©ä½™ {len(ips_to_lookup) - processed_count} ä¸ªIP")
                break

            # å¤„ç†å¤šIPåœ°å€çš„æƒ…å†µ
            original_ip = ip
            if "," in ip or " " in ip:
                # å–ç¬¬ä¸€ä¸ªIPè¿›è¡Œè§£æ
                first_ip = ip.split(",")[0].strip()
                logging.debug(f"ğŸ”„ å¤šIPåœ°å€å¤„ç†: '{ip}' -> ä½¿ç”¨ç¬¬ä¸€ä¸ªIP '{first_ip}' è¿›è¡Œåœ°ç†ä¿¡æ¯è§£æ")
                ip = first_ip
            elif not ip:
                logging.warning("è·³è¿‡ç©ºIPåœ°å€")
                skipped_count += 1
                continue

            logging.debug(f"ğŸ” æŸ¥è¯¢IP: {ip}")
            geo_data = ip_geo_manager.lookup_ip(ip)

            if geo_data:
                logging.debug(f"ğŸ“ è§£ææˆåŠŸ: {ip} -> {geo_data.get('city', 'N/A')}, {geo_data.get('country_name', 'N/A')}")

                geo_info = {
                    "country_code": geo_data.get("country_code"),
                    "country_name": geo_data.get("country_name"),
                    "city": geo_data.get("city"),
                    "latitude": geo_data.get("latitude"),
                    "longitude": geo_data.get("longitude"),
                    "mmdb_version": "1.0",
                    "geo_updated_at": datetime.utcnow(),
                }

                try:
                    # æ›´æ–°æ‰€æœ‰è¯¥IPçš„è®¿é—®è®°å½•
                    update_result = db.access_logs.update_many({"ip": original_ip}, {"$set": {"geo_info": geo_info}})
                    logging.debug(f"ğŸ’¾ æ›´æ–°è®¿é—®è®°å½•: '{original_ip}' -> {update_result.modified_count} æ¡è®°å½•")

                    # ä¿å­˜åˆ°ç¼“å­˜
                    geo_doc = {"ip": ip, **geo_info}
                    db.ip_geo_cache.replace_one({"ip": ip}, geo_doc, upsert=True)
                    logging.debug(f"ğŸ’¾ ä¿å­˜åˆ°ç¼“å­˜: {ip}")

                    # æ›´æ–°itemsä¸­çš„åœ°ç†ä¿¡æ¯
                    for item in items:
                        if item["ip"] == original_ip:
                            item["geo_info"] = geo_info
                            break

                    processed_count += 1

                except Exception as e:
                    logging.warning(f"âŒ æ›´æ–°IP {ip} åœ°ç†ä¿¡æ¯å¤±è´¥: {e}")
                    skipped_count += 1
            else:
                logging.debug(f"â“ æ— æ³•è§£æIP: {ip} (å¯èƒ½æ˜¯ç§æœ‰IPæˆ–æ— è®°å½•)")
                skipped_count += 1

        # æ€»ç»“æ—¥å¿—
        logging.info("ğŸ“Š æ‰¹é‡æ›´æ–°å®Œæˆ:")
        logging.info(f"  - æ–°è§£æå¹¶åµŒå…¥: {processed_count} ä¸ªIP")
        logging.info(f"  - è·³è¿‡/å¤±è´¥: {skipped_count} ä¸ªIP")
        logging.info(f"  - å‰©ä½™æœªå¤„ç†: {len(ips_to_lookup) - processed_count} ä¸ªIP")

        if processed_count > 0:
            logging.info(f"ğŸ‰ æˆåŠŸæ›´æ–°äº† {processed_count} ä¸ªIPçš„åœ°ç†ä¿¡æ¯åˆ°è®¿é—®è®°å½•ä¸­")

    except Exception as e:
        logging.error(f"âŒ æ‰¹é‡æ›´æ–°åœ°ç†ä¿¡æ¯å¤±è´¥: {e}", exc_info=True)


# --- PDFå¤„ç†API ---
@admin_bp.route("/api/pdf/upload", methods=["POST"])
@admin_required
def upload_pdf():
    """ä¸Šä¼ PDFæ–‡ä»¶å¹¶å¼€å§‹å¤„ç†"""
    try:
        if "pdf_file" not in request.files:
            return jsonify({"error": "æ²¡æœ‰ä¸Šä¼ æ–‡ä»¶"}), 400

        file = request.files["pdf_file"]
        if file.filename == "":
            return jsonify({"error": "æ²¡æœ‰é€‰æ‹©æ–‡ä»¶"}), 400

        if not file.filename.lower().endswith(".pdf"):
            return jsonify({"error": "åªæ”¯æŒPDFæ–‡ä»¶"}), 400

        university_name = request.form.get("university_name", "").strip()
        if not university_name:
            return jsonify({"error": "è¯·è¾“å…¥å¤§å­¦åç§°"}), 400

        # è·å–å¤„ç†æ¨¡å¼
        processing_mode = request.form.get("processing_mode", "normal").strip()
        if processing_mode not in ["normal", "batch"]:
            return jsonify({"error": "æ— æ•ˆçš„å¤„ç†æ¨¡å¼"}), 400

        # ä¿å­˜æ–‡ä»¶åˆ°ä¸´æ—¶ç›®å½•
        original_filename = file.filename
        safe_filename = secure_filename(file.filename)
        temp_filename = f"{uuid.uuid4().hex}_{safe_filename}"

        temp_dir = os.path.join(tempfile.gettempdir(), "pdf_uploads")
        os.makedirs(temp_dir, exist_ok=True)

        temp_filepath = os.path.join(temp_dir, temp_filename)
        file.save(temp_filepath)

        # åˆ›å»ºå¤„ç†ä»»åŠ¡
        task_id = task_manager.create_task(
            university_name=university_name,
            pdf_file_path=temp_filepath,
            original_filename=original_filename,
            processing_mode=processing_mode,
        )

        if task_id:
            return jsonify({"message": "ä»»åŠ¡åˆ›å»ºæˆåŠŸ", "task_id": task_id})
        else:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            try:
                os.remove(temp_filepath)
            except OSError:
                pass
            return jsonify({"error": "åˆ›å»ºä»»åŠ¡å¤±è´¥"}), 500

    except Exception as e:
        logging.error(f"[Admin API] PDFä¸Šä¼ å¤±è´¥: {e}", exc_info=True)
        return jsonify({"error": "æœåŠ¡å™¨å†…éƒ¨é”™è¯¯"}), 500


@admin_bp.route("/api/pdf/tasks", methods=["GET"])
@admin_required
def get_pdf_tasks():
    """è·å–PDFå¤„ç†ä»»åŠ¡åˆ—è¡¨"""
    try:
        limit = request.args.get("limit", 50, type=int)
        tasks = task_manager.get_all_tasks(limit=limit)

        # æ ¼å¼åŒ–æ—¶é—´
        for task in tasks:
            if "created_at" in task:
                task["created_at_str"] = task["created_at"].strftime("%Y-%m-%d %H:%M:%S")
            if "updated_at" in task:
                task["updated_at_str"] = task["updated_at"].strftime("%Y-%m-%d %H:%M:%S")

        return jsonify(tasks)

    except Exception as e:
        logging.error(f"[Admin API] è·å–PDFä»»åŠ¡åˆ—è¡¨å¤±è´¥: {e}", exc_info=True)
        return jsonify({"error": "æœåŠ¡å™¨å†…éƒ¨é”™è¯¯"}), 500


@admin_bp.route("/api/pdf/task/<task_id>", methods=["GET"])
@admin_required
def get_pdf_task(task_id):
    """è·å–å•ä¸ªPDFå¤„ç†ä»»åŠ¡çš„è¯¦ç»†ä¿¡æ¯"""
    try:
        task = task_manager.get_task_status(task_id)
        if not task:
            return jsonify({"error": "ä»»åŠ¡ä¸å­˜åœ¨"}), 404

        # æ ¼å¼åŒ–æ—¶é—´
        if "created_at" in task:
            task["created_at_str"] = task["created_at"].strftime("%Y-%m-%d %H:%M:%S")
        if "updated_at" in task:
            task["updated_at_str"] = task["updated_at"].strftime("%Y-%m-%d %H:%M:%S")

        # æ ¼å¼åŒ–æ—¥å¿—æ—¶é—´
        if "logs" in task:
            for log in task["logs"]:
                if "timestamp" in log:
                    log["timestamp_str"] = log["timestamp"].strftime("%H:%M:%S")

        return jsonify(task)

    except Exception as e:
        logging.error(f"[Admin API] è·å–PDFä»»åŠ¡è¯¦æƒ…å¤±è´¥: {e}", exc_info=True)
        return jsonify({"error": "æœåŠ¡å™¨å†…éƒ¨é”™è¯¯"}), 500


@admin_bp.route("/api/pdf/queue_status", methods=["GET"])
@admin_required
def get_queue_status():
    """è·å–å¤„ç†é˜Ÿåˆ—çŠ¶æ€"""
    try:
        status = task_manager.get_queue_status()
        return jsonify(status)
    except Exception as e:
        logging.error(f"[Admin API] è·å–é˜Ÿåˆ—çŠ¶æ€å¤±è´¥: {e}", exc_info=True)
        return jsonify({"error": "æœåŠ¡å™¨å†…éƒ¨é”™è¯¯"}), 500


@admin_bp.route("/api/thread_pool/status", methods=["GET"])
@admin_required
def get_thread_pool_status():
    """è·å–çº¿ç¨‹æ± çŠ¶æ€"""
    try:
        stats = thread_pool_manager.get_pool_stats()
        return jsonify(stats)
    except Exception as e:
        logging.error(f"[Admin API] è·å–çº¿ç¨‹æ± çŠ¶æ€å¤±è´¥: {e}", exc_info=True)
        return jsonify({"error": "æœåŠ¡å™¨å†…éƒ¨é”™è¯¯"}), 500


@admin_bp.route("/api/dashboard-stream")
@admin_required
def dashboard_stream():
    """ä½¿ç”¨SSEæ¨é€ä»ªè¡¨ç›˜çš„å®æ—¶æ•°æ®"""

    def event_stream():
        last_data = None
        while True:
            try:
                stats_data = _get_dashboard_stats()
                pool_data = thread_pool_manager.get_pool_stats()
                combined_data = {"stats": stats_data, "pools": pool_data}
                current_data = json.dumps(combined_data, default=str)

                # ä»…åœ¨æ•°æ®å˜åŒ–æ—¶å‘é€
                if current_data != last_data:
                    yield f"data: {current_data}\n\n"
                    last_data = current_data

            except Exception as e:
                logging.error(f"Error in SSE dashboard stream: {e}", exc_info=True)
                error_data = json.dumps({"error": "An internal error occurred"})
                yield f"event: error\ndata: {error_data}\n\n"

            # æ¯30ç§’æ£€æŸ¥ä¸€æ¬¡
            time.sleep(30)

    return Response(event_stream(), mimetype="text/event-stream")


@admin_bp.route("/api/pdf/task-stream/<task_id>")
@admin_required
def task_detail_stream(task_id):
    """ä½¿ç”¨SSEæ¨é€å•ä¸ªä»»åŠ¡çš„è¯¦ç»†æ›´æ–°"""

    def event_stream():
        last_task_data = None
        while True:
            try:
                task = task_manager.get_task_status(task_id)
                if not task:
                    error_data = json.dumps({"error": "Task not found"})
                    yield f"event: error\ndata: {error_data}\n\n"
                    break

                current_task_data = json.dumps(task, default=str)

                if current_task_data != last_task_data:
                    # æ ¼å¼åŒ–æ—¶é—´æˆ³
                    if "created_at" in task and hasattr(task["created_at"], "strftime"):
                        task["created_at_str"] = task["created_at"].strftime("%Y-%m-%d %H:%M:%S")
                    if "updated_at" in task and hasattr(task["updated_at"], "strftime"):
                        task["updated_at_str"] = task["updated_at"].strftime("%Y-%m-%d %H:%M:%S")
                    if "logs" in task:
                        for log in task["logs"]:
                            if "timestamp" in log and hasattr(log["timestamp"], "strftime"):
                                log["timestamp_str"] = log["timestamp"].strftime("%H:%M:%S")

                    json_data = json.dumps(task, default=str)
                    yield f"data: {json_data}\n\n"
                    last_task_data = current_task_data

                # å¦‚æœä»»åŠ¡å®Œæˆæˆ–å¤±è´¥ï¼Œåˆ™åœæ­¢æ¨é€
                if task.get("status") in ["completed", "failed"]:
                    break

            except Exception as e:
                logging.error(
                    f"Error in SSE task detail stream for task {task_id}: {e}",
                    exc_info=True,
                )
                error_data = json.dumps({"error": "An internal error occurred"})
                yield f"event: error\ndata: {error_data}\n\n"
                break

            time.sleep(30)

    return Response(event_stream(), mimetype="text/event-stream")


@admin_bp.route("/api/pdf/task/<task_id>/restart", methods=["POST"])
@admin_required
def restart_task(task_id):
    """ä»æŒ‡å®šæ­¥éª¤é‡å¯ä»»åŠ¡"""
    try:
        data = request.get_json()

        if not data or "step_name" not in data:
            return jsonify({"error": "ç¼ºå°‘æ­¥éª¤åç§°å‚æ•°"}), 400

        step_name = data["step_name"]

        # éªŒè¯æ­¥éª¤åç§°
        valid_steps = [
            "01_pdf2img",
            "02_ocr",
            "03_translate",
            "04_analysis",
            "05_output",
        ]
        if step_name not in valid_steps:
            return jsonify({"error": f"æ— æ•ˆçš„æ­¥éª¤åç§°ï¼Œæœ‰æ•ˆæ­¥éª¤: {valid_steps}"}), 400

        success = task_manager.restart_task_from_step(task_id, step_name)

        if success:
            return jsonify({"message": f"ä»»åŠ¡å·²è®¾ç½®ä¸ºä»æ­¥éª¤ {step_name} é‡å¯"})
        else:
            return jsonify({"error": "é‡å¯ä»»åŠ¡å¤±è´¥"}), 500

    except Exception as e:
        logging.error(f"[Admin API] é‡å¯ä»»åŠ¡å¤±è´¥: {e}", exc_info=True)
        return jsonify({"error": "æœåŠ¡å™¨å†…éƒ¨é”™è¯¯"}), 500


@admin_bp.route("/api/pdf/task/<task_id>/start", methods=["POST"])
@admin_required
def start_pending_task(task_id):
    """æ‰‹åŠ¨å¯åŠ¨å¾…å¤„ç†çš„ä»»åŠ¡"""
    try:
        success = task_manager.start_pending_task(task_id)

        if success:
            return jsonify({"message": "ä»»åŠ¡å·²æ·»åŠ åˆ°å¤„ç†é˜Ÿåˆ—"})
        else:
            return jsonify({"error": "å¯åŠ¨ä»»åŠ¡å¤±è´¥"}), 500

    except Exception as e:
        logging.error(f"[Admin API] å¯åŠ¨ä»»åŠ¡å¤±è´¥: {e}", exc_info=True)
        return jsonify({"error": "æœåŠ¡å™¨å†…éƒ¨é”™è¯¯"}), 500


@admin_bp.route("/api/pdf/queue/process", methods=["POST"])
@admin_required
def process_queue():
    """æ‰‹åŠ¨è§¦å‘é˜Ÿåˆ—å¤„ç†"""
    try:
        # æ¢å¤å¾…å¤„ç†ä»»åŠ¡åˆ°é˜Ÿåˆ—
        task_manager.recover_pending_tasks()
        # å¤„ç†é˜Ÿåˆ—
        task_manager.process_queue()
        # è·å–é˜Ÿåˆ—çŠ¶æ€
        queue_status = task_manager.get_queue_status()

        return jsonify({"message": "é˜Ÿåˆ—å¤„ç†å·²è§¦å‘", "queue_status": queue_status})

    except Exception as e:
        logging.error(f"[Admin API] æ‰‹åŠ¨å¤„ç†é˜Ÿåˆ—å¤±è´¥: {e}", exc_info=True)
        return jsonify({"error": "æœåŠ¡å™¨å†…éƒ¨é”™è¯¯"}), 500
